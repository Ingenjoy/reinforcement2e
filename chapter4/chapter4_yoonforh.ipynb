{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Policy Evaluation (Prediction)\n",
    "### Exercise 4.1 (Example 4.1 4X4 gridworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rough interfaces\n",
    "class Agent(object) :\n",
    "    def __init__(self, env, policy) :\n",
    "        self.env = env\n",
    "        self.policy = policy\n",
    "        self.time = 0\n",
    "    \n",
    "    def step(self) :\n",
    "        current_state = self.env.state()\n",
    "        action = self.policy.get_action(current_state)\n",
    "        reward = self.env.action(action)\n",
    "        new_state = self.env.state()\n",
    "        self.state_changed(self.time, action, current_state, new_state, reward)\n",
    "        self.time = self.time + 1\n",
    "\n",
    "    def state_changed(self, time, action, old_state, new_state, reward) :\n",
    "        pass\n",
    "    \n",
    "class Environment(object) :\n",
    "    def state(self) :\n",
    "        pass\n",
    "    \n",
    "    def is_terminal_state(self) :\n",
    "        return False\n",
    "    \n",
    "    def action(self, act) : # transit states and return reward\n",
    "        pass\n",
    "\n",
    "    def check_dynamics(self, state, act) : # give state, action and get next state and reward\n",
    "        pass\n",
    "\n",
    "class Policy(object) :\n",
    "    def get_action(self, state) :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from enum import IntEnum\n",
    "\n",
    "class Move(IntEnum) :\n",
    "    UP = 0\n",
    "    DOWN = 1\n",
    "    RIGHT = 2\n",
    "    LEFT = 3\n",
    "    \n",
    "    def get_deltas(direction) :\n",
    "        deltas_dic = { Move.UP : (-1, 0), Move.DOWN : (1, 0), Move.RIGHT : (0, 1), Move.LEFT : (0, -1) }\n",
    "        return deltas_dic.get(direction)\n",
    "    \n",
    "    def get_arrow(direction) :\n",
    "        arrow_dic = { Move.UP : '↑', Move.DOWN : '↓', Move.RIGHT : '←', Move.LEFT : '→' }\n",
    "        return arrow_dic.get(direction)\n",
    "\n",
    "class GridWorld(Environment) :\n",
    "    def __init__(self, initial_state) :\n",
    "        self.initialize_states()\n",
    "        super(Environment, self).__init__()\n",
    "        self.state = initial_state\n",
    "        \n",
    "    def initialize_states(self) :\n",
    "        self.grid = np.empty((4, 4), dtype=np.int32)\n",
    "        self.grid[0, 0] = self.grid[3, 3] = -1\n",
    "        for i in range(1, 15) :\n",
    "            self.grid[i//4, i - (i//4) * 4] = i\n",
    "        # print('self.grid:', self.grid)\n",
    "\n",
    "    def reset_state(self, new_state) :\n",
    "        self.state = new_state\n",
    "        \n",
    "    def state_to_grid(self, state) :\n",
    "        return (state // 4, state - (state // 4) * 4)\n",
    "    \n",
    "    def grid_to_state(self, row, col) :\n",
    "        return self.grid[row, col]\n",
    "    \n",
    "    def is_terminal_state(self) :\n",
    "        return self.state == -1\n",
    "\n",
    "    def action(self, act) : # transit states and return reward\n",
    "        if self.is_terminal_state() :\n",
    "            print('already reached the terminal state')\n",
    "            return 0\n",
    "        \n",
    "        current_grid = self.state_to_grid(self.state)\n",
    "        next_grid = np.add(current_grid, Move.get_deltas(act))\n",
    "        if next_grid[0] < 0 or next_grid[0] >= 4 or next_grid[1] < 0 or next_grid[1] >= 4 :\n",
    "            print('invalid move')\n",
    "        else :\n",
    "            self.state = self.grid_to_state(next_grid[0], next_grid[1])\n",
    "        return -1\n",
    "\n",
    "    def check_dynamics(self, state, act) : # give state, action and get next state and reward\n",
    "        if state == -1 : # terminal state\n",
    "            return -1, 0\n",
    "        \n",
    "        current_grid = self.state_to_grid(state)\n",
    "        next_grid = np.add(current_grid, Move.get_deltas(act))\n",
    "        if next_grid[0] < 0 or next_grid[0] >= 4 or next_grid[1] < 0 or next_grid[1] >= 4 :\n",
    "            next_state = state\n",
    "        else :\n",
    "            next_state = self.grid_to_state(next_grid[0], next_grid[1])\n",
    "        # print('next_grid:', next_grid, ',next_state:', next_state)\n",
    "\n",
    "        return next_state, -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridPolicy(Policy) :\n",
    "    def __init__(self) :\n",
    "        self.grid = np.zeros((4, 4, 4), dtype=np.float32)\n",
    "\n",
    "    def select_greedy(values) :\n",
    "        indices = np.concatenate(np.where(values == values.max()))\n",
    "        if len(indices) > 1 : # if we remember prev decision, then we can optimize to select by round-robin\n",
    "            idx = np.random.randint(0, len(indices))\n",
    "            return indices[idx]\n",
    "        return indices[0]\n",
    "\n",
    "    def _select_greedy_all(values) :\n",
    "        return np.concatenate(np.where(values == values.max()))\n",
    "    \n",
    "    def _state_to_grid(self, state) :\n",
    "        return (state // 4, state - (state // 4) * 4)\n",
    "\n",
    "    def values(self, state) :\n",
    "        return self.grid[self._state_to_grid(state)]\n",
    "\n",
    "    def set_value(self, state, action, value) :\n",
    "        self.grid[self._state_to_grid(state)][int(action)] = value\n",
    "\n",
    "    def set_values(self, state, values) :\n",
    "        self.grid[self._state_to_grid(state)] = values\n",
    "        \n",
    "    def get_action(self, state) :\n",
    "        values = self.values(state)\n",
    "        action_idx = GridPolicy.select_greedy(values)\n",
    "        return Move(action_idx)\n",
    "\n",
    "    def get_action_indices(self, state) :\n",
    "        values = self.values(state)\n",
    "        return GridPolicy._select_greedy_all(values)\n",
    "    \n",
    "    def get_actions_str(self, state) :\n",
    "        values = self.values(state)\n",
    "        indices = GridPolicy._select_greedy_all(values)\n",
    "        str = ''\n",
    "        for idx in indices :\n",
    "            str = str + Move.get_arrow(Move(idx))\n",
    "        # print('indices:', indices, ',str:', str)\n",
    "        return str\n",
    "    \n",
    "    def print_policy(self) :\n",
    "        policy = np.chararray((4, 4), itemsize=4, unicode=True)\n",
    "        for state in range(1, 15) :\n",
    "            policy[self._state_to_grid(state)] = self.get_actions_str(state)\n",
    "        print(policy)\n",
    "\n",
    "    def print_policy_values(self) :\n",
    "        for state in range(1, 15) :\n",
    "            print('state [', state, '], values :', self.grid[self._state_to_grid(state)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Evaluation Agent\n",
    "\n",
    "class GridPolicyEvaluationAgent(Agent) :\n",
    "    theta = 0.01\n",
    "    \n",
    "    def __init__(self, env, policy, gamma=1.0) :\n",
    "        super(GridPolicyEvaluationAgent, self).__init__(env, policy)\n",
    "        self.state_values = np.zeros((4, 4), dtype=np.float32)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def _state_to_grid(self, state) :\n",
    "        return (state // 4, state - (state // 4) * 4)\n",
    "        \n",
    "    def state_changed(self, time, action, old_state, new_state, reward) :\n",
    "        # now we need to update values\n",
    "        pass\n",
    "\n",
    "    def run(self) :\n",
    "        k = 0\n",
    "        #while True :\n",
    "        for k in range(30) :\n",
    "            delta = 0\n",
    "            for state in range(1, 15) :\n",
    "                v = self.state_values[self._state_to_grid(state)]\n",
    "                \n",
    "                new_v = 0.0\n",
    "                for action in range(4) :\n",
    "                    next_state, r = env.check_dynamics(state, Move(action))\n",
    "                    # print('next state :', next_state)\n",
    "                    new_v = new_v + 0.25 * (r + self.gamma * self.state_values[self._state_to_grid(next_state)])\n",
    "                \n",
    "                self.state_values[self._state_to_grid(state)] = new_v # update in-place\n",
    "                delta = max(delta, abs(new_v - v))\n",
    "            if delta < GridPolicyEvaluationAgent.theta :\n",
    "                print('delta (', delta, ') is less than theta (', GridPolicyEvaluationAgent.theta,\n",
    "                      '), so breaks the loop...')\n",
    "                break\n",
    "            k = k + 1\n",
    "            print('current state-values (k =', k, ') :')\n",
    "            print(self.state_values)\n",
    "        \n",
    "        #print('final policy values :')\n",
    "        # self.policy.print_policy_values()\n",
    "        print('final state-values :')\n",
    "        print(self.state_values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current state-values (k = 1 ) :\n",
      "[[ 0.        -1.        -1.25      -1.3125   ]\n",
      " [-1.        -1.5       -1.6875    -1.75     ]\n",
      " [-1.25      -1.6875    -1.84375   -1.8984375]\n",
      " [-1.3125    -1.75      -1.8984375  0.       ]]\n",
      "current state-values (k = 2 ) :\n",
      "[[ 0.        -1.9375    -2.546875  -2.7304688]\n",
      " [-1.9375    -2.8125    -3.2382812 -3.4042969]\n",
      " [-2.546875  -3.2382812 -3.5683594 -3.2177734]\n",
      " [-2.7304688 -3.4042969 -3.2177734  0.       ]]\n",
      "current state-values (k = 3 ) :\n",
      "[[ 0.        -2.8242188 -3.834961  -4.175049 ]\n",
      " [-2.8242188 -4.03125   -4.709717  -4.876709 ]\n",
      " [-3.834961  -4.709717  -4.963745  -4.264557 ]\n",
      " [-4.175049  -4.876709  -4.264557   0.       ]]\n",
      "current state-values (k = 4 ) :\n",
      "[[ 0.        -3.6726074 -5.0980835 -5.5812225]\n",
      " [-3.6726074 -5.191162  -6.032425  -6.1887283]\n",
      " [-5.0980835 -6.032425  -6.148491  -5.150444 ]\n",
      " [-5.5812225 -6.1887283 -5.150444   0.       ]]\n",
      "current state-values (k = 5 ) :\n",
      "[[ 0.        -4.4904633 -6.3005486 -6.9129305]\n",
      " [-4.4904633 -6.261444  -7.224803  -7.3692265]\n",
      " [-6.3005486 -7.224803  -7.1876235 -5.9268236]\n",
      " [-6.9129305 -7.3692265 -5.9268236  0.       ]]\n",
      "current state-values (k = 6 ) :\n",
      "[[ 0.        -5.263114  -7.425349  -8.155109 ]\n",
      " [-5.263114  -7.2439585 -8.30654   -8.4394245]\n",
      " [-7.425349  -8.30654   -8.116682  -6.6207323]\n",
      " [-8.155109  -8.4394245 -6.6207323  0.       ]]\n",
      "current state-values (k = 7 ) :\n",
      "[[ 0.        -5.9831057 -8.4675255 -9.304293 ]\n",
      " [-5.9831057 -8.144823  -9.292114  -9.414141 ]\n",
      " [-8.4675255 -9.292114  -8.956423  -7.2478237]\n",
      " [-9.304293  -9.414141  -7.2478237  0.       ]]\n",
      "current state-values (k = 8 ) :\n",
      "[[  0.         -6.648864   -9.428199  -10.362731 ]\n",
      " [ -6.648864   -8.9704895 -10.192313  -10.304253 ]\n",
      " [ -9.428199  -10.192313   -9.720068   -7.818036 ]\n",
      " [-10.362731  -10.304253   -7.818036    0.       ]]\n",
      "current state-values (k = 9 ) :\n",
      "[[  0.         -7.261888  -10.311283  -11.335249 ]\n",
      " [ -7.261888   -9.7271    -11.0156765 -11.118303 ]\n",
      " [-10.311283  -11.0156765 -10.416857   -8.338299 ]\n",
      " [-11.335249  -11.118303   -8.338299    0.       ]]\n",
      "current state-values (k = 10 ) :\n",
      "[[  0.         -7.825068  -11.1218195 -12.227655 ]\n",
      " [ -7.825068  -10.420372  -11.769338  -11.863399 ]\n",
      " [-11.1218195 -11.769338  -11.053818   -8.813879 ]\n",
      " [-12.227655  -11.863399   -8.813879    0.       ]]\n",
      "current state-values (k = 11 ) :\n",
      "[[  0.        -8.341815 -11.865157 -13.045967]\n",
      " [ -8.341815 -11.055576 -12.459488 -12.545683]\n",
      " [-11.865157 -12.459488 -11.636683  -9.249062]\n",
      " [-13.045967 -12.545683  -9.249062   0.      ]]\n",
      "current state-values (k = 12 ) :\n",
      "[[  0.        -8.815638 -12.546562 -13.796045]\n",
      " [ -8.815638 -11.637563 -13.091623 -13.170603]\n",
      " [-12.546562 -13.091623 -12.170342  -9.647502]\n",
      " [-13.796045 -13.170603  -9.647502   0.      ]]\n",
      "current state-values (k = 13 ) :\n",
      "[[  0.        -9.249941 -13.171043 -14.483435]\n",
      " [ -9.249941 -12.170782 -13.670692 -13.743058]\n",
      " [-13.171043 -13.670692 -12.659098 -10.012415]\n",
      " [-14.483435 -13.743058 -10.012415   0.      ]]\n",
      "current state-values (k = 14 ) :\n",
      "[[  0.         -9.647942  -13.7432785 -15.113301 ]\n",
      " [ -9.647942  -12.659317  -14.201188  -14.26749  ]\n",
      " [-13.7432785 -14.201188  -13.106802  -10.346677 ]\n",
      " [-15.113301  -14.26749   -10.346677    0.       ]]\n",
      "current state-values (k = 15 ) :\n",
      "[[  0.       -10.012634 -14.267601 -15.690424]\n",
      " [-10.012634 -13.106911 -14.687201 -14.747948]\n",
      " [-14.267601 -14.687201 -13.516939 -10.652891]\n",
      " [-15.690424 -14.747948 -10.652891   0.      ]]\n",
      "current state-values (k = 16 ) :\n",
      "[[  0.        -10.3467865 -14.748003  -16.2192   ]\n",
      " [-10.3467865 -13.5169935 -15.132471  -15.1881275]\n",
      " [-14.748003  -15.132471  -13.892681  -10.933425 ]\n",
      " [-16.2192    -15.1881275 -10.933425    0.       ]]\n",
      "current state-values (k = 17 ) :\n",
      "[[  0.        -10.6529455 -15.188155  -16.70367  ]\n",
      " [-10.6529455 -13.892708  -15.540418  -15.59141  ]\n",
      " [-15.188155  -15.540418  -14.236921  -11.190439 ]\n",
      " [-16.70367   -15.59141   -11.190439    0.       ]]\n",
      "current state-values (k = 18 ) :\n",
      "[[  0.       -10.933453 -15.591424 -17.147543]\n",
      " [-10.933453 -14.236935 -15.914172 -15.960891]\n",
      " [-15.591424 -15.914172 -14.552305 -11.425909]\n",
      " [-17.147543 -15.960891 -11.425909   0.      ]]\n",
      "current state-values (k = 19 ) :\n",
      "[[  0.       -11.190453 -15.960897 -17.554218]\n",
      " [-11.190453 -14.552313 -16.256601 -16.299404]\n",
      " [-15.960897 -16.256601 -14.841255 -11.641642]\n",
      " [-17.554218 -16.299404 -11.641642   0.      ]]\n",
      "current state-values (k = 20 ) :\n",
      "[[  0.        -11.425916  -16.299408  -17.926811 ]\n",
      " [-11.425916  -14.841259  -16.570332  -16.609547 ]\n",
      " [-16.299408  -16.570332  -15.105987  -11.8392935]\n",
      " [-17.926811  -16.609547  -11.8392935   0.       ]]\n",
      "current state-values (k = 21 ) :\n",
      "[[  0.        -11.641645  -16.609549  -18.268179 ]\n",
      " [-11.641645  -15.1059885 -16.857767  -16.893696 ]\n",
      " [-16.609549  -16.857767  -15.34853   -12.02038  ]\n",
      " [-18.268179  -16.893696  -12.02038     0.       ]]\n",
      "current state-values (k = 22 ) :\n",
      "[[  0.       -11.839295 -16.893698 -18.580938]\n",
      " [-11.839295 -15.348532 -17.121113 -17.154032]\n",
      " [-16.893698 -17.121113 -15.570746 -12.18629 ]\n",
      " [-18.580938 -17.154032 -12.18629    0.      ]]\n",
      "current state-values (k = 23 ) :\n",
      "[[  0.       -12.020381 -17.154032 -18.867485]\n",
      " [-12.020381 -15.570747 -17.362389 -17.39255 ]\n",
      " [-17.154032 -17.362389 -15.77434  -12.338295]\n",
      " [-18.867485 -17.39255  -12.338295   0.      ]]\n",
      "current state-values (k = 24 ) :\n",
      "[[  0.       -12.18629  -17.39255  -19.130016]\n",
      " [-12.18629  -15.77434  -17.583445 -17.611076]\n",
      " [-17.39255  -17.583445 -15.96087  -12.47756 ]\n",
      " [-19.130016 -17.611076 -12.47756    0.      ]]\n",
      "current state-values (k = 25 ) :\n",
      "[[  0.       -12.338295 -17.611076 -19.370546]\n",
      " [-12.338295 -15.96087  -17.785973 -17.811289]\n",
      " [-17.611076 -17.785973 -16.131767 -12.605154]\n",
      " [-19.370546 -17.811289 -12.605154   0.      ]]\n",
      "current state-values (k = 26 ) :\n",
      "[[  0.        -12.47756   -17.811289  -19.590918 ]\n",
      " [-12.47756   -16.131767  -17.971527  -17.994722 ]\n",
      " [-17.811289  -17.971527  -16.288342  -12.7220545]\n",
      " [-19.590918  -17.994722  -12.7220545   0.       ]]\n",
      "current state-values (k = 27 ) :\n",
      "[[  0.       -12.605154 -17.994722 -19.79282 ]\n",
      " [-12.605154 -16.288342 -18.141533 -18.162783]\n",
      " [-17.994722 -18.141533 -16.431793 -12.829158]\n",
      " [-19.79282  -18.162783 -12.829158   0.      ]]\n",
      "current state-values (k = 28 ) :\n",
      "[[  0.        -12.7220545 -18.162783  -19.977802 ]\n",
      " [-12.7220545 -16.431793  -18.297287  -18.316757 ]\n",
      " [-18.162783  -18.297287  -16.563223  -12.927284 ]\n",
      " [-19.977802  -18.316757  -12.927284    0.       ]]\n",
      "current state-values (k = 29 ) :\n",
      "[[  0.       -12.829158 -18.316757 -20.14728 ]\n",
      " [-12.829158 -16.563223 -18.439991 -18.457829]\n",
      " [-18.316757 -18.439991 -16.683638 -13.017187]\n",
      " [-20.14728  -18.457829 -13.017187   0.      ]]\n",
      "current state-values (k = 30 ) :\n",
      "[[  0.       -12.927284 -18.457829 -20.302555]\n",
      " [-12.927284 -16.683638 -18.570732 -18.587076]\n",
      " [-18.457829 -18.570732 -16.79396  -13.099556]\n",
      " [-20.302555 -18.587076 -13.099556   0.      ]]\n",
      "final state-values :\n",
      "[[  0.       -12.927284 -18.457829 -20.302555]\n",
      " [-12.927284 -16.683638 -18.570732 -18.587076]\n",
      " [-18.457829 -18.570732 -16.79396  -13.099556]\n",
      " [-20.302555 -18.587076 -13.099556   0.      ]]\n"
     ]
    }
   ],
   "source": [
    "env = GridWorld(np.random.randint(1, 14))\n",
    "policy = GridPolicy()\n",
    "\n",
    "agent = GridPolicyEvaluationAgent(env, policy, gamma=1.0)\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Iteration Agent\n",
    "\n",
    "class GridPolicyIterationAgent(Agent) :\n",
    "    theta = 0.01\n",
    "    \n",
    "    def __init__(self, env, policy, gamma=1.0) :\n",
    "        super(GridPolicyIterationAgent, self).__init__(env, policy)\n",
    "        self.state_values = np.zeros((4, 4), dtype=np.float32)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def _state_to_grid(self, state) :\n",
    "        return (state // 4, state - (state // 4) * 4)\n",
    "        \n",
    "    def state_changed(self, time, action, old_state, new_state, reward) :\n",
    "        # now we need to update values\n",
    "        pass\n",
    "\n",
    "    def eval_policy(self) : \n",
    "        k = 0\n",
    "        #while True :\n",
    "        for k in range(30) :\n",
    "            delta = 0\n",
    "            for state in range(1, 15) :\n",
    "                v = self.state_values[self._state_to_grid(state)]\n",
    "                \n",
    "                new_v = 0.0\n",
    "                for action in range(4) :\n",
    "                    next_state, r = env.check_dynamics(state, Move(action))\n",
    "                    # print('next state :', next_state)\n",
    "                    new_v = new_v + 0.25 * (r + self.gamma * self.state_values[self._state_to_grid(next_state)])\n",
    "                \n",
    "                self.state_values[self._state_to_grid(state)] = new_v # update in-place\n",
    "                delta = max(delta, abs(new_v - v))\n",
    "            if delta < GridPolicyEvaluationAgent.theta :\n",
    "                print('delta (', delta, ') is less than theta (', GridPolicyEvaluationAgent.theta,\n",
    "                      '), so breaks the loop...')\n",
    "                break\n",
    "            k = k + 1\n",
    "            print('current state-values (k =', k, ') :')\n",
    "            print(self.state_values)\n",
    "        \n",
    "        #print('final policy values :')\n",
    "        # self.policy.print_policy_values()\n",
    "        print('final state-values :')\n",
    "        print(self.state_values)\n",
    "        \n",
    "    def improve_policy(self) : # return False if policy is stable (not improved)\n",
    "        policy_stable = True\n",
    "        for state in range(1, 15) :\n",
    "            current_action_indices = policy.get_action_indices(state)\n",
    "            for action in range(4) :\n",
    "                next_state, r = env.check_dynamics(state, Move(action))\n",
    "                # print('next state :', next_state)\n",
    "                policy.set_value(state, Move(action), r + self.gamma * self.state_values[self._state_to_grid(next_state)])\n",
    "            new_action_indices = policy.get_action_indices(state)\n",
    "            if not np.array_equal(current_action_indices, new_action_indices) :\n",
    "                policy_stable = False\n",
    "        print('improved policy :')\n",
    "        policy.print_policy()\n",
    "        return policy_stable\n",
    "    \n",
    "    def run(self) :\n",
    "        continous_stable_count = 0\n",
    "        print('initial policy :')\n",
    "        policy.print_policy()\n",
    "        for loop in range(30) :\n",
    "            self.eval_policy()\n",
    "            if self.improve_policy() :\n",
    "                print('policy is stable in the loop :', loop)\n",
    "                continous_stable_count = continous_stable_count + 1\n",
    "                if continous_stable_count > 2 :\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial policy :\n",
      "[['' '↑↓←→' '↑↓←→' '↑↓←→']\n",
      " ['↑↓←→' '↑↓←→' '↑↓←→' '↑↓←→']\n",
      " ['↑↓←→' '↑↓←→' '↑↓←→' '↑↓←→']\n",
      " ['↑↓←→' '↑↓←→' '↑↓←→' '']]\n",
      "current state-values (k = 1 ) :\n",
      "[[ 0.        -1.        -1.25      -1.3125   ]\n",
      " [-1.        -1.5       -1.6875    -1.75     ]\n",
      " [-1.25      -1.6875    -1.84375   -1.8984375]\n",
      " [-1.3125    -1.75      -1.8984375  0.       ]]\n",
      "current state-values (k = 2 ) :\n",
      "[[ 0.        -1.9375    -2.546875  -2.7304688]\n",
      " [-1.9375    -2.8125    -3.2382812 -3.4042969]\n",
      " [-2.546875  -3.2382812 -3.5683594 -3.2177734]\n",
      " [-2.7304688 -3.4042969 -3.2177734  0.       ]]\n",
      "current state-values (k = 3 ) :\n",
      "[[ 0.        -2.8242188 -3.834961  -4.175049 ]\n",
      " [-2.8242188 -4.03125   -4.709717  -4.876709 ]\n",
      " [-3.834961  -4.709717  -4.963745  -4.264557 ]\n",
      " [-4.175049  -4.876709  -4.264557   0.       ]]\n",
      "current state-values (k = 4 ) :\n",
      "[[ 0.        -3.6726074 -5.0980835 -5.5812225]\n",
      " [-3.6726074 -5.191162  -6.032425  -6.1887283]\n",
      " [-5.0980835 -6.032425  -6.148491  -5.150444 ]\n",
      " [-5.5812225 -6.1887283 -5.150444   0.       ]]\n",
      "current state-values (k = 5 ) :\n",
      "[[ 0.        -4.4904633 -6.3005486 -6.9129305]\n",
      " [-4.4904633 -6.261444  -7.224803  -7.3692265]\n",
      " [-6.3005486 -7.224803  -7.1876235 -5.9268236]\n",
      " [-6.9129305 -7.3692265 -5.9268236  0.       ]]\n",
      "current state-values (k = 6 ) :\n",
      "[[ 0.        -5.263114  -7.425349  -8.155109 ]\n",
      " [-5.263114  -7.2439585 -8.30654   -8.4394245]\n",
      " [-7.425349  -8.30654   -8.116682  -6.6207323]\n",
      " [-8.155109  -8.4394245 -6.6207323  0.       ]]\n",
      "current state-values (k = 7 ) :\n",
      "[[ 0.        -5.9831057 -8.4675255 -9.304293 ]\n",
      " [-5.9831057 -8.144823  -9.292114  -9.414141 ]\n",
      " [-8.4675255 -9.292114  -8.956423  -7.2478237]\n",
      " [-9.304293  -9.414141  -7.2478237  0.       ]]\n",
      "current state-values (k = 8 ) :\n",
      "[[  0.         -6.648864   -9.428199  -10.362731 ]\n",
      " [ -6.648864   -8.9704895 -10.192313  -10.304253 ]\n",
      " [ -9.428199  -10.192313   -9.720068   -7.818036 ]\n",
      " [-10.362731  -10.304253   -7.818036    0.       ]]\n",
      "current state-values (k = 9 ) :\n",
      "[[  0.         -7.261888  -10.311283  -11.335249 ]\n",
      " [ -7.261888   -9.7271    -11.0156765 -11.118303 ]\n",
      " [-10.311283  -11.0156765 -10.416857   -8.338299 ]\n",
      " [-11.335249  -11.118303   -8.338299    0.       ]]\n",
      "current state-values (k = 10 ) :\n",
      "[[  0.         -7.825068  -11.1218195 -12.227655 ]\n",
      " [ -7.825068  -10.420372  -11.769338  -11.863399 ]\n",
      " [-11.1218195 -11.769338  -11.053818   -8.813879 ]\n",
      " [-12.227655  -11.863399   -8.813879    0.       ]]\n",
      "current state-values (k = 11 ) :\n",
      "[[  0.        -8.341815 -11.865157 -13.045967]\n",
      " [ -8.341815 -11.055576 -12.459488 -12.545683]\n",
      " [-11.865157 -12.459488 -11.636683  -9.249062]\n",
      " [-13.045967 -12.545683  -9.249062   0.      ]]\n",
      "current state-values (k = 12 ) :\n",
      "[[  0.        -8.815638 -12.546562 -13.796045]\n",
      " [ -8.815638 -11.637563 -13.091623 -13.170603]\n",
      " [-12.546562 -13.091623 -12.170342  -9.647502]\n",
      " [-13.796045 -13.170603  -9.647502   0.      ]]\n",
      "current state-values (k = 13 ) :\n",
      "[[  0.        -9.249941 -13.171043 -14.483435]\n",
      " [ -9.249941 -12.170782 -13.670692 -13.743058]\n",
      " [-13.171043 -13.670692 -12.659098 -10.012415]\n",
      " [-14.483435 -13.743058 -10.012415   0.      ]]\n",
      "current state-values (k = 14 ) :\n",
      "[[  0.         -9.647942  -13.7432785 -15.113301 ]\n",
      " [ -9.647942  -12.659317  -14.201188  -14.26749  ]\n",
      " [-13.7432785 -14.201188  -13.106802  -10.346677 ]\n",
      " [-15.113301  -14.26749   -10.346677    0.       ]]\n",
      "current state-values (k = 15 ) :\n",
      "[[  0.       -10.012634 -14.267601 -15.690424]\n",
      " [-10.012634 -13.106911 -14.687201 -14.747948]\n",
      " [-14.267601 -14.687201 -13.516939 -10.652891]\n",
      " [-15.690424 -14.747948 -10.652891   0.      ]]\n",
      "current state-values (k = 16 ) :\n",
      "[[  0.        -10.3467865 -14.748003  -16.2192   ]\n",
      " [-10.3467865 -13.5169935 -15.132471  -15.1881275]\n",
      " [-14.748003  -15.132471  -13.892681  -10.933425 ]\n",
      " [-16.2192    -15.1881275 -10.933425    0.       ]]\n",
      "current state-values (k = 17 ) :\n",
      "[[  0.        -10.6529455 -15.188155  -16.70367  ]\n",
      " [-10.6529455 -13.892708  -15.540418  -15.59141  ]\n",
      " [-15.188155  -15.540418  -14.236921  -11.190439 ]\n",
      " [-16.70367   -15.59141   -11.190439    0.       ]]\n",
      "current state-values (k = 18 ) :\n",
      "[[  0.       -10.933453 -15.591424 -17.147543]\n",
      " [-10.933453 -14.236935 -15.914172 -15.960891]\n",
      " [-15.591424 -15.914172 -14.552305 -11.425909]\n",
      " [-17.147543 -15.960891 -11.425909   0.      ]]\n",
      "current state-values (k = 19 ) :\n",
      "[[  0.       -11.190453 -15.960897 -17.554218]\n",
      " [-11.190453 -14.552313 -16.256601 -16.299404]\n",
      " [-15.960897 -16.256601 -14.841255 -11.641642]\n",
      " [-17.554218 -16.299404 -11.641642   0.      ]]\n",
      "current state-values (k = 20 ) :\n",
      "[[  0.        -11.425916  -16.299408  -17.926811 ]\n",
      " [-11.425916  -14.841259  -16.570332  -16.609547 ]\n",
      " [-16.299408  -16.570332  -15.105987  -11.8392935]\n",
      " [-17.926811  -16.609547  -11.8392935   0.       ]]\n",
      "current state-values (k = 21 ) :\n",
      "[[  0.        -11.641645  -16.609549  -18.268179 ]\n",
      " [-11.641645  -15.1059885 -16.857767  -16.893696 ]\n",
      " [-16.609549  -16.857767  -15.34853   -12.02038  ]\n",
      " [-18.268179  -16.893696  -12.02038     0.       ]]\n",
      "current state-values (k = 22 ) :\n",
      "[[  0.       -11.839295 -16.893698 -18.580938]\n",
      " [-11.839295 -15.348532 -17.121113 -17.154032]\n",
      " [-16.893698 -17.121113 -15.570746 -12.18629 ]\n",
      " [-18.580938 -17.154032 -12.18629    0.      ]]\n",
      "current state-values (k = 23 ) :\n",
      "[[  0.       -12.020381 -17.154032 -18.867485]\n",
      " [-12.020381 -15.570747 -17.362389 -17.39255 ]\n",
      " [-17.154032 -17.362389 -15.77434  -12.338295]\n",
      " [-18.867485 -17.39255  -12.338295   0.      ]]\n",
      "current state-values (k = 24 ) :\n",
      "[[  0.       -12.18629  -17.39255  -19.130016]\n",
      " [-12.18629  -15.77434  -17.583445 -17.611076]\n",
      " [-17.39255  -17.583445 -15.96087  -12.47756 ]\n",
      " [-19.130016 -17.611076 -12.47756    0.      ]]\n",
      "current state-values (k = 25 ) :\n",
      "[[  0.       -12.338295 -17.611076 -19.370546]\n",
      " [-12.338295 -15.96087  -17.785973 -17.811289]\n",
      " [-17.611076 -17.785973 -16.131767 -12.605154]\n",
      " [-19.370546 -17.811289 -12.605154   0.      ]]\n",
      "current state-values (k = 26 ) :\n",
      "[[  0.        -12.47756   -17.811289  -19.590918 ]\n",
      " [-12.47756   -16.131767  -17.971527  -17.994722 ]\n",
      " [-17.811289  -17.971527  -16.288342  -12.7220545]\n",
      " [-19.590918  -17.994722  -12.7220545   0.       ]]\n",
      "current state-values (k = 27 ) :\n",
      "[[  0.       -12.605154 -17.994722 -19.79282 ]\n",
      " [-12.605154 -16.288342 -18.141533 -18.162783]\n",
      " [-17.994722 -18.141533 -16.431793 -12.829158]\n",
      " [-19.79282  -18.162783 -12.829158   0.      ]]\n",
      "current state-values (k = 28 ) :\n",
      "[[  0.        -12.7220545 -18.162783  -19.977802 ]\n",
      " [-12.7220545 -16.431793  -18.297287  -18.316757 ]\n",
      " [-18.162783  -18.297287  -16.563223  -12.927284 ]\n",
      " [-19.977802  -18.316757  -12.927284    0.       ]]\n",
      "current state-values (k = 29 ) :\n",
      "[[  0.       -12.829158 -18.316757 -20.14728 ]\n",
      " [-12.829158 -16.563223 -18.439991 -18.457829]\n",
      " [-18.316757 -18.439991 -16.683638 -13.017187]\n",
      " [-20.14728  -18.457829 -13.017187   0.      ]]\n",
      "current state-values (k = 30 ) :\n",
      "[[  0.       -12.927284 -18.457829 -20.302555]\n",
      " [-12.927284 -16.683638 -18.570732 -18.587076]\n",
      " [-18.457829 -18.570732 -16.79396  -13.099556]\n",
      " [-20.302555 -18.587076 -13.099556   0.      ]]\n",
      "final state-values :\n",
      "[[  0.       -12.927284 -18.457829 -20.302555]\n",
      " [-12.927284 -16.683638 -18.570732 -18.587076]\n",
      " [-18.457829 -18.570732 -16.79396  -13.099556]\n",
      " [-20.302555 -18.587076 -13.099556   0.      ]]\n",
      "improved policy :\n",
      "[['' '→' '→' '→']\n",
      " ['↑' '↑→' '→' '↓']\n",
      " ['↑' '↑' '↓←' '↓']\n",
      " ['↑' '←' '←' '']]\n",
      "current state-values (k = 1 ) :\n",
      "[[  0.       -13.017187 -18.587076 -20.444817]\n",
      " [-13.017187 -16.79396  -18.690517 -18.705492]\n",
      " [-18.587076 -18.690517 -16.895037 -13.175021]\n",
      " [-20.444817 -18.705492 -13.175021   0.      ]]\n",
      "current state-values (k = 2 ) :\n",
      "[[  0.       -13.099556 -18.705492 -20.575153]\n",
      " [-13.099556 -16.895037 -18.800264 -18.813982]\n",
      " [-18.705492 -18.800264 -16.987642 -13.244162]\n",
      " [-20.575153 -18.813982 -13.244162   0.      ]]\n",
      "current state-values (k = 3 ) :\n",
      "[[  0.        -13.175021  -18.813982  -20.694569 ]\n",
      " [-13.175021  -16.987642  -18.900812  -18.913382 ]\n",
      " [-18.813982  -18.900812  -17.072487  -13.3075075]\n",
      " [-20.694569  -18.913382  -13.3075075   0.       ]]\n",
      "current state-values (k = 4 ) :\n",
      "[[  0.       -13.244162 -18.913382 -20.803974]\n",
      " [-13.244162 -17.072487 -18.992935 -19.00445 ]\n",
      " [-18.913382 -18.992935 -17.15022  -13.365544]\n",
      " [-20.803974 -19.00445  -13.365544   0.      ]]\n",
      "current state-values (k = 5 ) :\n",
      "[[  0.        -13.3075075 -19.00445   -20.904213 ]\n",
      " [-13.3075075 -17.15022   -19.077335  -19.087885 ]\n",
      " [-19.00445   -19.077335  -17.22144   -13.418717 ]\n",
      " [-20.904213  -19.087885  -13.418717    0.       ]]\n",
      "current state-values (k = 6 ) :\n",
      "[[  0.       -13.365544 -19.087885 -20.996048]\n",
      " [-13.365544 -17.22144  -19.154663 -19.164328]\n",
      " [-19.087885 -19.154663 -17.28669  -13.467434]\n",
      " [-20.996048 -19.164328 -13.467434   0.      ]]\n",
      "current state-values (k = 7 ) :\n",
      "[[  0.       -13.418717 -19.164328 -21.080189]\n",
      " [-13.418717 -17.28669  -19.22551  -19.234365]\n",
      " [-19.164328 -19.22551  -17.346472 -13.512068]\n",
      " [-21.080189 -19.234365 -13.512068   0.      ]]\n",
      "current state-values (k = 8 ) :\n",
      "[[  0.       -13.467434 -19.234365 -21.157276]\n",
      " [-13.467434 -17.346472 -19.290419 -19.298532]\n",
      " [-19.234365 -19.290419 -17.401243 -13.552961]\n",
      " [-21.157276 -19.298532 -13.552961   0.      ]]\n",
      "current state-values (k = 9 ) :\n",
      "[[  0.       -13.512068 -19.298532 -21.227905]\n",
      " [-13.512068 -17.401243 -19.349888 -19.357323]\n",
      " [-19.298532 -19.349888 -17.451424 -13.590427]\n",
      " [-21.227905 -19.357323 -13.590427   0.      ]]\n",
      "current state-values (k = 10 ) :\n",
      "[[  0.       -13.552961 -19.357323 -21.292614]\n",
      " [-13.552961 -17.451424 -19.404373 -19.411184]\n",
      " [-19.357323 -19.404373 -17.4974   -13.624753]\n",
      " [-21.292614 -19.411184 -13.624753   0.      ]]\n",
      "current state-values (k = 11 ) :\n",
      "[[  0.       -13.590427 -19.411184 -21.351898]\n",
      " [-13.590427 -17.4974   -19.454292 -19.460531]\n",
      " [-19.411184 -19.454292 -17.539522 -13.656201]\n",
      " [-21.351898 -19.460531 -13.656201   0.      ]]\n",
      "current state-values (k = 12 ) :\n",
      "[[  0.       -13.624753 -19.460531 -21.406216]\n",
      " [-13.624753 -17.539522 -19.500027 -19.505743]\n",
      " [-19.460531 -19.500027 -17.578114 -13.685015]\n",
      " [-21.406216 -19.505743 -13.685015   0.      ]]\n",
      "current state-values (k = 13 ) :\n",
      "[[  0.       -13.656201 -19.505743 -21.455978]\n",
      " [-13.656201 -17.578114 -19.541927 -19.547165]\n",
      " [-19.505743 -19.541927 -17.613472 -13.711412]\n",
      " [-21.455978 -19.547165 -13.711412   0.      ]]\n",
      "current state-values (k = 14 ) :\n",
      "[[  0.        -13.685015  -19.547165  -21.501572 ]\n",
      " [-13.685015  -17.613472  -19.580318  -19.585117 ]\n",
      " [-19.547165  -19.580318  -17.645866  -13.7355995]\n",
      " [-21.501572  -19.585117  -13.7355995   0.       ]]\n",
      "current state-values (k = 15 ) :\n",
      "[[  0.       -13.711412 -19.585117 -21.543344]\n",
      " [-13.711412 -17.645866 -19.615492 -19.619888]\n",
      " [-19.585117 -19.615492 -17.675545 -13.757758]\n",
      " [-21.543344 -19.619888 -13.757758   0.      ]]\n",
      "current state-values (k = 16 ) :\n",
      "[[  0.        -13.7355995 -19.619888  -21.581615 ]\n",
      " [-13.7355995 -17.675545  -19.647717  -19.651745 ]\n",
      " [-19.619888  -19.647717  -17.702738  -13.77806  ]\n",
      " [-21.581615  -19.651745  -13.77806     0.       ]]\n",
      "current state-values (k = 17 ) :\n",
      "[[  0.       -13.757758 -19.651745 -21.61668 ]\n",
      " [-13.757758 -17.702738 -19.677242 -19.680931]\n",
      " [-19.651745 -19.677242 -17.727652 -13.79666 ]\n",
      " [-21.61668  -19.680931 -13.79666    0.      ]]\n",
      "current state-values (k = 18 ) :\n",
      "[[  0.       -13.77806  -19.680931 -21.648806]\n",
      " [-13.77806  -17.727652 -19.704292 -19.707672]\n",
      " [-19.680931 -19.704292 -17.750477 -13.813703]\n",
      " [-21.648806 -19.707672 -13.813703   0.      ]]\n",
      "current state-values (k = 19 ) :\n",
      "[[  0.       -13.79666  -19.707672 -21.678238]\n",
      " [-13.79666  -17.750477 -19.729074 -19.732172]\n",
      " [-19.707672 -19.729074 -17.771389 -13.829316]\n",
      " [-21.678238 -19.732172 -13.829316   0.      ]]\n",
      "current state-values (k = 20 ) :\n",
      "[[  0.       -13.813703 -19.732172 -21.705204]\n",
      " [-13.813703 -17.771389 -19.751781 -19.754618]\n",
      " [-19.732172 -19.751781 -17.790548 -13.84362 ]\n",
      " [-21.705204 -19.754618 -13.84362    0.      ]]\n",
      "current state-values (k = 21 ) :\n",
      "[[  0.       -13.829316 -19.754618 -21.729912]\n",
      " [-13.829316 -17.790548 -19.772583 -19.775183]\n",
      " [-19.754618 -19.772583 -17.808102 -13.856726]\n",
      " [-21.729912 -19.775183 -13.856726   0.      ]]\n",
      "current state-values (k = 22 ) :\n",
      "[[  0.       -13.84362  -19.775183 -21.752548]\n",
      " [-13.84362  -17.808102 -19.791641 -19.794025]\n",
      " [-19.775183 -19.791641 -17.824184 -13.868734]\n",
      " [-21.752548 -19.794025 -13.868734   0.      ]]\n",
      "current state-values (k = 23 ) :\n",
      "[[  0.       -13.856726 -19.794025 -21.773287]\n",
      " [-13.856726 -17.824184 -19.809105 -19.811287]\n",
      " [-19.794025 -19.809105 -17.83892  -13.879736]\n",
      " [-21.773287 -19.811287 -13.879736   0.      ]]\n",
      "current state-values (k = 24 ) :\n",
      "[[  0.       -13.868734 -19.811287 -21.792286]\n",
      " [-13.868734 -17.83892  -19.825104 -19.827103]\n",
      " [-19.811287 -19.825104 -17.85242  -13.889814]\n",
      " [-21.792286 -19.827103 -13.889814   0.      ]]\n",
      "current state-values (k = 25 ) :\n",
      "[[  0.       -13.879736 -19.827103 -21.809694]\n",
      " [-13.879736 -17.85242  -19.839762 -19.841593]\n",
      " [-19.827103 -19.839762 -17.864788 -13.899049]\n",
      " [-21.809694 -19.841593 -13.899049   0.      ]]\n",
      "current state-values (k = 26 ) :\n",
      "[[  0.       -13.889814 -19.841593 -21.825644]\n",
      " [-13.889814 -17.864788 -19.853191 -19.85487 ]\n",
      " [-19.841593 -19.853191 -17.87612  -13.90751 ]\n",
      " [-21.825644 -19.85487  -13.90751    0.      ]]\n",
      "current state-values (k = 27 ) :\n",
      "[[  0.       -13.899049 -19.85487  -21.840256]\n",
      " [-13.899049 -17.87612  -19.865494 -19.867033]\n",
      " [-19.85487  -19.865494 -17.886501 -13.915261]\n",
      " [-21.840256 -19.867033 -13.915261   0.      ]]\n",
      "current state-values (k = 28 ) :\n",
      "[[  0.       -13.90751  -19.867033 -21.853645]\n",
      " [-13.90751  -17.886501 -19.876766 -19.878176]\n",
      " [-19.867033 -19.876766 -17.896013 -13.922362]\n",
      " [-21.853645 -19.878176 -13.922362   0.      ]]\n",
      "current state-values (k = 29 ) :\n",
      "[[  0.       -13.915261 -19.878176 -21.86591 ]\n",
      " [-13.915261 -17.896013 -19.887094 -19.888386]\n",
      " [-19.878176 -19.887094 -17.904728 -13.928869]\n",
      " [-21.86591  -19.888386 -13.928869   0.      ]]\n",
      "current state-values (k = 30 ) :\n",
      "[[  0.       -13.922362 -19.888386 -21.877148]\n",
      " [-13.922362 -17.904728 -19.896557 -19.89774 ]\n",
      " [-19.888386 -19.896557 -17.912712 -13.93483 ]\n",
      " [-21.877148 -19.89774  -13.93483    0.      ]]\n",
      "final state-values :\n",
      "[[  0.       -13.922362 -19.888386 -21.877148]\n",
      " [-13.922362 -17.904728 -19.896557 -19.89774 ]\n",
      " [-19.888386 -19.896557 -17.912712 -13.93483 ]\n",
      " [-21.877148 -19.89774  -13.93483    0.      ]]\n",
      "improved policy :\n",
      "[['' '→' '→' '→']\n",
      " ['↑' '↑→' '→' '↓']\n",
      " ['↑' '↑' '↓←' '↓']\n",
      " ['↑' '←' '←' '']]\n",
      "policy is stable in the loop : 1\n",
      "current state-values (k = 1 ) :\n",
      "[[  0.       -13.928869 -19.89774  -21.887444]\n",
      " [-13.928869 -17.912712 -19.905226 -19.90631 ]\n",
      " [-19.89774  -19.905226 -17.920029 -13.940292]\n",
      " [-21.887444 -19.90631  -13.940292   0.      ]]\n",
      "delta ( 0.009432792663574219 ) is less than theta ( 0.01 ), so breaks the loop...\n",
      "final state-values :\n",
      "[[  0.       -13.93483  -19.90631  -21.896877]\n",
      " [-13.93483  -17.920029 -19.91317  -19.914162]\n",
      " [-19.90631  -19.91317  -17.926731 -13.945296]\n",
      " [-21.896877 -19.914162 -13.945296   0.      ]]\n",
      "improved policy :\n",
      "[['' '→' '→' '→']\n",
      " ['↑' '↑→' '→' '↓']\n",
      " ['↑' '↑' '↓←' '↓']\n",
      " ['↑' '←' '←' '']]\n",
      "policy is stable in the loop : 2\n",
      "delta ( 0.008642196655273438 ) is less than theta ( 0.01 ), so breaks the loop...\n",
      "final state-values :\n",
      "[[  0.       -13.940292 -19.914162 -21.90552 ]\n",
      " [-13.940292 -17.926731 -19.920446 -19.921356]\n",
      " [-19.914162 -19.920446 -17.93287  -13.949881]\n",
      " [-21.90552  -19.921356 -13.949881   0.      ]]\n",
      "improved policy :\n",
      "[['' '→' '→' '→']\n",
      " ['↑' '↑→' '→' '↓']\n",
      " ['↑' '↑' '↓←' '↓']\n",
      " ['↑' '←' '←' '']]\n",
      "policy is stable in the loop : 3\n"
     ]
    }
   ],
   "source": [
    "# create policy\n",
    "policy = GridPolicy()\n",
    "agent = GridPolicyIterationAgent(env, policy, gamma=1.0)\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['' '' '' '']\n",
      " ['' 'abcd' '' '']\n",
      " ['' '' '' '']\n",
      " ['' '' '' '']]\n"
     ]
    }
   ],
   "source": [
    "policy = np.chararray((4, 4), itemsize=4, unicode=True)\n",
    "policy[1, 1] = 'abcd'\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.3 (equation h/w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Policy Iteration\n",
    "### Exercise 4.7 (Example 4.2 Jack's Car Rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Value Iteration\n",
    "### Exercise 4.9 (Example 4.3 Gambler's Problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.10 (equation h/w)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow)",
   "language": "python",
   "name": "py3tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
