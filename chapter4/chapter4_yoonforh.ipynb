{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Policy Evaluation (Prediction)\n",
    "### Exercise 4.1 (Example 4.1 4X4 gridworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rough interfaces\n",
    "class Agent(object) :\n",
    "    def __init__(self, env, policy) :\n",
    "        self.env = env\n",
    "        self.policy = policy\n",
    "        self.time = 0\n",
    "    \n",
    "    def step(self) :\n",
    "        current_state = self.env.state()\n",
    "        action = self.policy.get_action(current_state)\n",
    "        reward = self.env.action(action)\n",
    "        new_state = self.env.state()\n",
    "        self.state_changed(self.time, action, current_state, new_state, reward)\n",
    "        self.time = self.time + 1\n",
    "\n",
    "    def state_changed(self, time, action, old_state, new_state, reward) :\n",
    "        pass\n",
    "    \n",
    "class Environment(object) :\n",
    "    def state(self) :\n",
    "        pass\n",
    "    \n",
    "    def is_terminal_state(self) :\n",
    "        return False\n",
    "    \n",
    "    def action(self, act) : # transit states and return reward\n",
    "        pass\n",
    "\n",
    "    def check_dynamics(self, state, act) : # give state, action and get next state and reward\n",
    "        pass\n",
    "\n",
    "class Policy(object) :\n",
    "    def get_action(self, state) :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from enum import IntEnum\n",
    "\n",
    "class Move(IntEnum) :\n",
    "    UP = 0\n",
    "    DOWN = 1\n",
    "    RIGHT = 2\n",
    "    LEFT = 3\n",
    "    \n",
    "    def get_deltas(direction) :\n",
    "        deltas_dic = { Move.UP : (-1, 0), Move.DOWN : (1, 0), Move.RIGHT : (0, 1), Move.LEFT : (0, -1) }\n",
    "        return deltas_dic.get(direction)\n",
    "    \n",
    "    def get_arrow(direction) :\n",
    "        arrow_dic = { Move.UP : '↑', Move.DOWN : '↓', Move.RIGHT : '←', Move.LEFT : '→' }\n",
    "        return arrow_dic.get(direction)\n",
    "\n",
    "class GridWorld(Environment) :\n",
    "    def __init__(self, initial_state) :\n",
    "        self.initialize_states()\n",
    "        super(Environment, self).__init__()\n",
    "        self.state = initial_state\n",
    "        \n",
    "    def initialize_states(self) :\n",
    "        self.grid = np.empty((4, 4), dtype=np.int32)\n",
    "        self.grid[0, 0] = self.grid[3, 3] = -1\n",
    "        for i in range(1, 15) :\n",
    "            self.grid[i//4, i - (i//4) * 4] = i\n",
    "        # print('self.grid:', self.grid)\n",
    "\n",
    "    def reset_state(self, new_state) :\n",
    "        self.state = new_state\n",
    "        \n",
    "    def state_to_grid(self, state) :\n",
    "        return (state // 4, state - (state // 4) * 4)\n",
    "    \n",
    "    def grid_to_state(self, row, col) :\n",
    "        return self.grid[row, col]\n",
    "    \n",
    "    def is_terminal_state(self) :\n",
    "        return self.state == -1\n",
    "\n",
    "    def action(self, act) : # transit states and return reward\n",
    "        if self.is_terminal_state() :\n",
    "            print('already reached the terminal state')\n",
    "            return 0\n",
    "        \n",
    "        current_grid = self.state_to_grid(self.state)\n",
    "        next_grid = np.add(current_grid, Move.get_deltas(act))\n",
    "        if next_grid[0] < 0 or next_grid[0] >= 4 or next_grid[1] < 0 or next_grid[1] >= 4 :\n",
    "            print('invalid move')\n",
    "        else :\n",
    "            self.state = self.grid_to_state(next_grid[0], next_grid[1])\n",
    "        return -1\n",
    "\n",
    "    def check_dynamics(self, state, act) : # give state, action and get next state and reward\n",
    "        if state == -1 : # terminal state\n",
    "            return -1, 0\n",
    "        \n",
    "        current_grid = self.state_to_grid(state)\n",
    "        next_grid = np.add(current_grid, Move.get_deltas(act))\n",
    "        if next_grid[0] < 0 or next_grid[0] >= 4 or next_grid[1] < 0 or next_grid[1] >= 4 :\n",
    "            next_state = state\n",
    "        else :\n",
    "            next_state = self.grid_to_state(next_grid[0], next_grid[1])\n",
    "        # print('next_grid:', next_grid, ',next_state:', next_state)\n",
    "\n",
    "        return next_state, -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridPolicy(Policy) :\n",
    "    def __init__(self) :\n",
    "        self.grid = np.zeros((4, 4, 4), dtype=np.float32)\n",
    "\n",
    "    def select_greedy(values) :\n",
    "        indices = np.concatenate(np.where(values == values.max()))\n",
    "        if len(indices) > 1 : # if we remember prev decision, then we can optimize to select by round-robin\n",
    "            idx = np.random.randint(0, len(indices))\n",
    "            return indices[idx]\n",
    "        return indices[0]\n",
    "\n",
    "    def _select_greedy_all(values) :\n",
    "        return np.concatenate(np.where(values == values.max()))\n",
    "    \n",
    "    def _state_to_grid(self, state) :\n",
    "        return (state // 4, state - (state // 4) * 4)\n",
    "\n",
    "    def values(self, state) :\n",
    "        return self.grid[self._state_to_grid(state)]\n",
    "\n",
    "    def set_value(self, state, action, value) :\n",
    "        self.grid[self._state_to_grid(state)][int(action)] = value\n",
    "\n",
    "    def set_values(self, state, values) :\n",
    "        self.grid[self._state_to_grid(state)] = values\n",
    "        \n",
    "    def get_action(self, state) :\n",
    "        values = self.values(state)\n",
    "        action_idx = GridPolicy.select_greedy(values)\n",
    "        return Move(action_idx)\n",
    "\n",
    "    def get_action_indices(self, state) :\n",
    "        values = self.values(state)\n",
    "        return GridPolicy._select_greedy_all(values)\n",
    "    \n",
    "    def get_actions_str(self, state) :\n",
    "        values = self.values(state)\n",
    "        indices = GridPolicy._select_greedy_all(values)\n",
    "        str = ''\n",
    "        for idx in indices :\n",
    "            str = str + Move.get_arrow(Move(idx))\n",
    "        # print('indices:', indices, ',str:', str)\n",
    "        return str\n",
    "    \n",
    "    def print_policy(self) :\n",
    "        policy = np.zeros((4, 4), dtype=np.str)\n",
    "        for state in range(1, 15) :\n",
    "            policy[self._state_to_grid(state)] = self.get_actions_str(state)\n",
    "        print(policy)\n",
    "\n",
    "    def print_policy_values(self) :\n",
    "        for state in range(1, 15) :\n",
    "            print('state [', state, '], values :', self.grid[self._state_to_grid(state)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Evaluation Agent\n",
    "\n",
    "class GridPolicyEvaluationAgent(Agent) :\n",
    "    theta = 0.01\n",
    "    \n",
    "    def __init__(self, env, policy, gamma=1.0) :\n",
    "        super(GridPolicyEvaluationAgent, self).__init__(env, policy)\n",
    "        self.state_values = np.zeros((4, 4), dtype=np.float32)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def _state_to_grid(self, state) :\n",
    "        return (state // 4, state - (state // 4) * 4)\n",
    "        \n",
    "    def state_changed(self, time, action, old_state, new_state, reward) :\n",
    "        # now we need to update values\n",
    "        pass\n",
    "\n",
    "    def run(self) :\n",
    "        k = 0\n",
    "        #while True :\n",
    "        for k in range(30) :\n",
    "            delta = 0\n",
    "            for state in range(1, 15) :\n",
    "                v = self.state_values[self._state_to_grid(state)]\n",
    "                \n",
    "                new_v = 0.0\n",
    "                for action in range(4) :\n",
    "                    next_state, r = env.check_dynamics(state, Move(action))\n",
    "                    # print('next state :', next_state)\n",
    "                    new_v = new_v + 0.25 * (r + self.gamma * self.state_values[self._state_to_grid(next_state)])\n",
    "                \n",
    "                self.state_values[self._state_to_grid(state)] = new_v # update in-place\n",
    "                delta = max(delta, abs(new_v - v))\n",
    "            if delta < GridPolicyEvaluationAgent.theta :\n",
    "                print('delta (', delta, ') is less than theta (', GridPolicyEvaluationAgent.theta,\n",
    "                      '), so breaks the loop...')\n",
    "                break\n",
    "            k = k + 1\n",
    "            print('current state-values (k =', k, ') :')\n",
    "            print(self.state_values)\n",
    "        \n",
    "        #print('final policy values :')\n",
    "        # self.policy.print_policy_values()\n",
    "        print('final state-values :')\n",
    "        print(self.state_values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current state-values (k = 1 ) :\n",
      "[[ 0.        -1.        -1.25      -1.3125   ]\n",
      " [-1.        -1.5       -1.6875    -1.75     ]\n",
      " [-1.25      -1.6875    -1.84375   -1.8984375]\n",
      " [-1.3125    -1.75      -1.8984375  0.       ]]\n",
      "current state-values (k = 2 ) :\n",
      "[[ 0.        -1.9375    -2.546875  -2.7304688]\n",
      " [-1.9375    -2.8125    -3.2382812 -3.4042969]\n",
      " [-2.546875  -3.2382812 -3.5683594 -3.2177734]\n",
      " [-2.7304688 -3.4042969 -3.2177734  0.       ]]\n",
      "current state-values (k = 3 ) :\n",
      "[[ 0.        -2.8242188 -3.834961  -4.175049 ]\n",
      " [-2.8242188 -4.03125   -4.709717  -4.876709 ]\n",
      " [-3.834961  -4.709717  -4.963745  -4.264557 ]\n",
      " [-4.175049  -4.876709  -4.264557   0.       ]]\n",
      "current state-values (k = 4 ) :\n",
      "[[ 0.        -3.6726074 -5.0980835 -5.5812225]\n",
      " [-3.6726074 -5.191162  -6.032425  -6.1887283]\n",
      " [-5.0980835 -6.032425  -6.148491  -5.150444 ]\n",
      " [-5.5812225 -6.1887283 -5.150444   0.       ]]\n",
      "current state-values (k = 5 ) :\n",
      "[[ 0.        -4.4904633 -6.3005486 -6.9129305]\n",
      " [-4.4904633 -6.261444  -7.224803  -7.3692265]\n",
      " [-6.3005486 -7.224803  -7.1876235 -5.9268236]\n",
      " [-6.9129305 -7.3692265 -5.9268236  0.       ]]\n",
      "current state-values (k = 6 ) :\n",
      "[[ 0.        -5.263114  -7.425349  -8.155109 ]\n",
      " [-5.263114  -7.2439585 -8.30654   -8.4394245]\n",
      " [-7.425349  -8.30654   -8.116682  -6.6207323]\n",
      " [-8.155109  -8.4394245 -6.6207323  0.       ]]\n",
      "current state-values (k = 7 ) :\n",
      "[[ 0.        -5.9831057 -8.4675255 -9.304293 ]\n",
      " [-5.9831057 -8.144823  -9.292114  -9.414141 ]\n",
      " [-8.4675255 -9.292114  -8.956423  -7.2478237]\n",
      " [-9.304293  -9.414141  -7.2478237  0.       ]]\n",
      "current state-values (k = 8 ) :\n",
      "[[  0.         -6.648864   -9.428199  -10.362731 ]\n",
      " [ -6.648864   -8.9704895 -10.192313  -10.304253 ]\n",
      " [ -9.428199  -10.192313   -9.720068   -7.818036 ]\n",
      " [-10.362731  -10.304253   -7.818036    0.       ]]\n",
      "current state-values (k = 9 ) :\n",
      "[[  0.         -7.261888  -10.311283  -11.335249 ]\n",
      " [ -7.261888   -9.7271    -11.0156765 -11.118303 ]\n",
      " [-10.311283  -11.0156765 -10.416857   -8.338299 ]\n",
      " [-11.335249  -11.118303   -8.338299    0.       ]]\n",
      "current state-values (k = 10 ) :\n",
      "[[  0.         -7.825068  -11.1218195 -12.227655 ]\n",
      " [ -7.825068  -10.420372  -11.769338  -11.863399 ]\n",
      " [-11.1218195 -11.769338  -11.053818   -8.813879 ]\n",
      " [-12.227655  -11.863399   -8.813879    0.       ]]\n",
      "current state-values (k = 11 ) :\n",
      "[[  0.        -8.341815 -11.865157 -13.045967]\n",
      " [ -8.341815 -11.055576 -12.459488 -12.545683]\n",
      " [-11.865157 -12.459488 -11.636683  -9.249062]\n",
      " [-13.045967 -12.545683  -9.249062   0.      ]]\n",
      "current state-values (k = 12 ) :\n",
      "[[  0.        -8.815638 -12.546562 -13.796045]\n",
      " [ -8.815638 -11.637563 -13.091623 -13.170603]\n",
      " [-12.546562 -13.091623 -12.170342  -9.647502]\n",
      " [-13.796045 -13.170603  -9.647502   0.      ]]\n",
      "current state-values (k = 13 ) :\n",
      "[[  0.        -9.249941 -13.171043 -14.483435]\n",
      " [ -9.249941 -12.170782 -13.670692 -13.743058]\n",
      " [-13.171043 -13.670692 -12.659098 -10.012415]\n",
      " [-14.483435 -13.743058 -10.012415   0.      ]]\n",
      "current state-values (k = 14 ) :\n",
      "[[  0.         -9.647942  -13.7432785 -15.113301 ]\n",
      " [ -9.647942  -12.659317  -14.201188  -14.26749  ]\n",
      " [-13.7432785 -14.201188  -13.106802  -10.346677 ]\n",
      " [-15.113301  -14.26749   -10.346677    0.       ]]\n",
      "current state-values (k = 15 ) :\n",
      "[[  0.       -10.012634 -14.267601 -15.690424]\n",
      " [-10.012634 -13.106911 -14.687201 -14.747948]\n",
      " [-14.267601 -14.687201 -13.516939 -10.652891]\n",
      " [-15.690424 -14.747948 -10.652891   0.      ]]\n",
      "current state-values (k = 16 ) :\n",
      "[[  0.        -10.3467865 -14.748003  -16.2192   ]\n",
      " [-10.3467865 -13.5169935 -15.132471  -15.1881275]\n",
      " [-14.748003  -15.132471  -13.892681  -10.933425 ]\n",
      " [-16.2192    -15.1881275 -10.933425    0.       ]]\n",
      "current state-values (k = 17 ) :\n",
      "[[  0.        -10.6529455 -15.188155  -16.70367  ]\n",
      " [-10.6529455 -13.892708  -15.540418  -15.59141  ]\n",
      " [-15.188155  -15.540418  -14.236921  -11.190439 ]\n",
      " [-16.70367   -15.59141   -11.190439    0.       ]]\n",
      "current state-values (k = 18 ) :\n",
      "[[  0.       -10.933453 -15.591424 -17.147543]\n",
      " [-10.933453 -14.236935 -15.914172 -15.960891]\n",
      " [-15.591424 -15.914172 -14.552305 -11.425909]\n",
      " [-17.147543 -15.960891 -11.425909   0.      ]]\n",
      "current state-values (k = 19 ) :\n",
      "[[  0.       -11.190453 -15.960897 -17.554218]\n",
      " [-11.190453 -14.552313 -16.256601 -16.299404]\n",
      " [-15.960897 -16.256601 -14.841255 -11.641642]\n",
      " [-17.554218 -16.299404 -11.641642   0.      ]]\n",
      "current state-values (k = 20 ) :\n",
      "[[  0.        -11.425916  -16.299408  -17.926811 ]\n",
      " [-11.425916  -14.841259  -16.570332  -16.609547 ]\n",
      " [-16.299408  -16.570332  -15.105987  -11.8392935]\n",
      " [-17.926811  -16.609547  -11.8392935   0.       ]]\n",
      "current state-values (k = 21 ) :\n",
      "[[  0.        -11.641645  -16.609549  -18.268179 ]\n",
      " [-11.641645  -15.1059885 -16.857767  -16.893696 ]\n",
      " [-16.609549  -16.857767  -15.34853   -12.02038  ]\n",
      " [-18.268179  -16.893696  -12.02038     0.       ]]\n",
      "current state-values (k = 22 ) :\n",
      "[[  0.       -11.839295 -16.893698 -18.580938]\n",
      " [-11.839295 -15.348532 -17.121113 -17.154032]\n",
      " [-16.893698 -17.121113 -15.570746 -12.18629 ]\n",
      " [-18.580938 -17.154032 -12.18629    0.      ]]\n",
      "current state-values (k = 23 ) :\n",
      "[[  0.       -12.020381 -17.154032 -18.867485]\n",
      " [-12.020381 -15.570747 -17.362389 -17.39255 ]\n",
      " [-17.154032 -17.362389 -15.77434  -12.338295]\n",
      " [-18.867485 -17.39255  -12.338295   0.      ]]\n",
      "current state-values (k = 24 ) :\n",
      "[[  0.       -12.18629  -17.39255  -19.130016]\n",
      " [-12.18629  -15.77434  -17.583445 -17.611076]\n",
      " [-17.39255  -17.583445 -15.96087  -12.47756 ]\n",
      " [-19.130016 -17.611076 -12.47756    0.      ]]\n",
      "current state-values (k = 25 ) :\n",
      "[[  0.       -12.338295 -17.611076 -19.370546]\n",
      " [-12.338295 -15.96087  -17.785973 -17.811289]\n",
      " [-17.611076 -17.785973 -16.131767 -12.605154]\n",
      " [-19.370546 -17.811289 -12.605154   0.      ]]\n",
      "current state-values (k = 26 ) :\n",
      "[[  0.        -12.47756   -17.811289  -19.590918 ]\n",
      " [-12.47756   -16.131767  -17.971527  -17.994722 ]\n",
      " [-17.811289  -17.971527  -16.288342  -12.7220545]\n",
      " [-19.590918  -17.994722  -12.7220545   0.       ]]\n",
      "current state-values (k = 27 ) :\n",
      "[[  0.       -12.605154 -17.994722 -19.79282 ]\n",
      " [-12.605154 -16.288342 -18.141533 -18.162783]\n",
      " [-17.994722 -18.141533 -16.431793 -12.829158]\n",
      " [-19.79282  -18.162783 -12.829158   0.      ]]\n",
      "current state-values (k = 28 ) :\n",
      "[[  0.        -12.7220545 -18.162783  -19.977802 ]\n",
      " [-12.7220545 -16.431793  -18.297287  -18.316757 ]\n",
      " [-18.162783  -18.297287  -16.563223  -12.927284 ]\n",
      " [-19.977802  -18.316757  -12.927284    0.       ]]\n",
      "current state-values (k = 29 ) :\n",
      "[[  0.       -12.829158 -18.316757 -20.14728 ]\n",
      " [-12.829158 -16.563223 -18.439991 -18.457829]\n",
      " [-18.316757 -18.439991 -16.683638 -13.017187]\n",
      " [-20.14728  -18.457829 -13.017187   0.      ]]\n",
      "current state-values (k = 30 ) :\n",
      "[[  0.       -12.927284 -18.457829 -20.302555]\n",
      " [-12.927284 -16.683638 -18.570732 -18.587076]\n",
      " [-18.457829 -18.570732 -16.79396  -13.099556]\n",
      " [-20.302555 -18.587076 -13.099556   0.      ]]\n",
      "final state-values :\n",
      "[[  0.       -12.927284 -18.457829 -20.302555]\n",
      " [-12.927284 -16.683638 -18.570732 -18.587076]\n",
      " [-18.457829 -18.570732 -16.79396  -13.099556]\n",
      " [-20.302555 -18.587076 -13.099556   0.      ]]\n"
     ]
    }
   ],
   "source": [
    "env = GridWorld(np.random.randint(1, 14))\n",
    "policy = GridPolicy()\n",
    "\n",
    "agent = GridPolicyEvaluationAgent(env, policy, gamma=1.0)\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Iteration Agent\n",
    "\n",
    "class GridPolicyIterationAgent(Agent) :\n",
    "    theta = 0.01\n",
    "    \n",
    "    def __init__(self, env, policy, gamma=1.0) :\n",
    "        super(GridPolicyIterationAgent, self).__init__(env, policy)\n",
    "        self.state_values = np.zeros((4, 4), dtype=np.float32)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def _state_to_grid(self, state) :\n",
    "        return (state // 4, state - (state // 4) * 4)\n",
    "        \n",
    "    def state_changed(self, time, action, old_state, new_state, reward) :\n",
    "        # now we need to update values\n",
    "        pass\n",
    "\n",
    "    def eval_policy(self) : \n",
    "        k = 0\n",
    "        #while True :\n",
    "        for k in range(30) :\n",
    "            delta = 0\n",
    "            for state in range(1, 15) :\n",
    "                v = self.state_values[self._state_to_grid(state)]\n",
    "                \n",
    "                new_v = 0.0\n",
    "                for action in range(4) :\n",
    "                    next_state, r = env.check_dynamics(state, Move(action))\n",
    "                    # print('next state :', next_state)\n",
    "                    new_v = new_v + 0.25 * (r + self.gamma * self.state_values[self._state_to_grid(next_state)])\n",
    "                \n",
    "                self.state_values[self._state_to_grid(state)] = new_v # update in-place\n",
    "                delta = max(delta, abs(new_v - v))\n",
    "            if delta < GridPolicyEvaluationAgent.theta :\n",
    "                print('delta (', delta, ') is less than theta (', GridPolicyEvaluationAgent.theta,\n",
    "                      '), so breaks the loop...')\n",
    "                break\n",
    "            k = k + 1\n",
    "            print('current state-values (k =', k, ') :')\n",
    "            print(self.state_values)\n",
    "        \n",
    "        #print('final policy values :')\n",
    "        # self.policy.print_policy_values()\n",
    "        print('final state-values :')\n",
    "        print(self.state_values)\n",
    "        \n",
    "    def improve_policy(self) : # return False if policy is stable (not improved)\n",
    "        policy_stable = True\n",
    "        for state in range(1, 15) :\n",
    "            current_action_indices = policy.get_action_indices(state)\n",
    "            for action in range(4) :\n",
    "                next_state, r = env.check_dynamics(state, Move(action))\n",
    "                # print('next state :', next_state)\n",
    "                policy.set_value(state, Move(action), r + self.gamma * self.state_values[self._state_to_grid(next_state)])\n",
    "            new_action_indices = policy.get_action_indices(state)\n",
    "            if not np.array_equal(current_action_indices, new_action_indices) :\n",
    "                policy_stable = False\n",
    "        return policy_stable\n",
    "    \n",
    "    def run(self) :\n",
    "        for loop in range(30) :\n",
    "            self.eval_policy()\n",
    "            if self.improve_policy() :\n",
    "                print('policy is stable in the loop :', loop)\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = [ 1, 2 ]\n",
    "b = [ 1, 2, 4]\n",
    "print(np.array_equal(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current state-values (k = 1 ) :\n",
      "[[ 0.        -1.        -1.25      -1.3125   ]\n",
      " [-1.        -1.5       -1.6875    -1.75     ]\n",
      " [-1.25      -1.6875    -1.84375   -1.8984375]\n",
      " [-1.3125    -1.75      -1.8984375  0.       ]]\n",
      "current state-values (k = 2 ) :\n",
      "[[ 0.        -1.9375    -2.546875  -2.7304688]\n",
      " [-1.9375    -2.8125    -3.2382812 -3.4042969]\n",
      " [-2.546875  -3.2382812 -3.5683594 -3.2177734]\n",
      " [-2.7304688 -3.4042969 -3.2177734  0.       ]]\n",
      "current state-values (k = 3 ) :\n",
      "[[ 0.        -2.8242188 -3.834961  -4.175049 ]\n",
      " [-2.8242188 -4.03125   -4.709717  -4.876709 ]\n",
      " [-3.834961  -4.709717  -4.963745  -4.264557 ]\n",
      " [-4.175049  -4.876709  -4.264557   0.       ]]\n",
      "current state-values (k = 4 ) :\n",
      "[[ 0.        -3.6726074 -5.0980835 -5.5812225]\n",
      " [-3.6726074 -5.191162  -6.032425  -6.1887283]\n",
      " [-5.0980835 -6.032425  -6.148491  -5.150444 ]\n",
      " [-5.5812225 -6.1887283 -5.150444   0.       ]]\n",
      "current state-values (k = 5 ) :\n",
      "[[ 0.        -4.4904633 -6.3005486 -6.9129305]\n",
      " [-4.4904633 -6.261444  -7.224803  -7.3692265]\n",
      " [-6.3005486 -7.224803  -7.1876235 -5.9268236]\n",
      " [-6.9129305 -7.3692265 -5.9268236  0.       ]]\n",
      "current state-values (k = 6 ) :\n",
      "[[ 0.        -5.263114  -7.425349  -8.155109 ]\n",
      " [-5.263114  -7.2439585 -8.30654   -8.4394245]\n",
      " [-7.425349  -8.30654   -8.116682  -6.6207323]\n",
      " [-8.155109  -8.4394245 -6.6207323  0.       ]]\n",
      "current state-values (k = 7 ) :\n",
      "[[ 0.        -5.9831057 -8.4675255 -9.304293 ]\n",
      " [-5.9831057 -8.144823  -9.292114  -9.414141 ]\n",
      " [-8.4675255 -9.292114  -8.956423  -7.2478237]\n",
      " [-9.304293  -9.414141  -7.2478237  0.       ]]\n",
      "current state-values (k = 8 ) :\n",
      "[[  0.         -6.648864   -9.428199  -10.362731 ]\n",
      " [ -6.648864   -8.9704895 -10.192313  -10.304253 ]\n",
      " [ -9.428199  -10.192313   -9.720068   -7.818036 ]\n",
      " [-10.362731  -10.304253   -7.818036    0.       ]]\n",
      "current state-values (k = 9 ) :\n",
      "[[  0.         -7.261888  -10.311283  -11.335249 ]\n",
      " [ -7.261888   -9.7271    -11.0156765 -11.118303 ]\n",
      " [-10.311283  -11.0156765 -10.416857   -8.338299 ]\n",
      " [-11.335249  -11.118303   -8.338299    0.       ]]\n",
      "current state-values (k = 10 ) :\n",
      "[[  0.         -7.825068  -11.1218195 -12.227655 ]\n",
      " [ -7.825068  -10.420372  -11.769338  -11.863399 ]\n",
      " [-11.1218195 -11.769338  -11.053818   -8.813879 ]\n",
      " [-12.227655  -11.863399   -8.813879    0.       ]]\n",
      "current state-values (k = 11 ) :\n",
      "[[  0.        -8.341815 -11.865157 -13.045967]\n",
      " [ -8.341815 -11.055576 -12.459488 -12.545683]\n",
      " [-11.865157 -12.459488 -11.636683  -9.249062]\n",
      " [-13.045967 -12.545683  -9.249062   0.      ]]\n",
      "current state-values (k = 12 ) :\n",
      "[[  0.        -8.815638 -12.546562 -13.796045]\n",
      " [ -8.815638 -11.637563 -13.091623 -13.170603]\n",
      " [-12.546562 -13.091623 -12.170342  -9.647502]\n",
      " [-13.796045 -13.170603  -9.647502   0.      ]]\n",
      "current state-values (k = 13 ) :\n",
      "[[  0.        -9.249941 -13.171043 -14.483435]\n",
      " [ -9.249941 -12.170782 -13.670692 -13.743058]\n",
      " [-13.171043 -13.670692 -12.659098 -10.012415]\n",
      " [-14.483435 -13.743058 -10.012415   0.      ]]\n",
      "current state-values (k = 14 ) :\n",
      "[[  0.         -9.647942  -13.7432785 -15.113301 ]\n",
      " [ -9.647942  -12.659317  -14.201188  -14.26749  ]\n",
      " [-13.7432785 -14.201188  -13.106802  -10.346677 ]\n",
      " [-15.113301  -14.26749   -10.346677    0.       ]]\n",
      "current state-values (k = 15 ) :\n",
      "[[  0.       -10.012634 -14.267601 -15.690424]\n",
      " [-10.012634 -13.106911 -14.687201 -14.747948]\n",
      " [-14.267601 -14.687201 -13.516939 -10.652891]\n",
      " [-15.690424 -14.747948 -10.652891   0.      ]]\n",
      "current state-values (k = 16 ) :\n",
      "[[  0.        -10.3467865 -14.748003  -16.2192   ]\n",
      " [-10.3467865 -13.5169935 -15.132471  -15.1881275]\n",
      " [-14.748003  -15.132471  -13.892681  -10.933425 ]\n",
      " [-16.2192    -15.1881275 -10.933425    0.       ]]\n",
      "current state-values (k = 17 ) :\n",
      "[[  0.        -10.6529455 -15.188155  -16.70367  ]\n",
      " [-10.6529455 -13.892708  -15.540418  -15.59141  ]\n",
      " [-15.188155  -15.540418  -14.236921  -11.190439 ]\n",
      " [-16.70367   -15.59141   -11.190439    0.       ]]\n",
      "current state-values (k = 18 ) :\n",
      "[[  0.       -10.933453 -15.591424 -17.147543]\n",
      " [-10.933453 -14.236935 -15.914172 -15.960891]\n",
      " [-15.591424 -15.914172 -14.552305 -11.425909]\n",
      " [-17.147543 -15.960891 -11.425909   0.      ]]\n",
      "current state-values (k = 19 ) :\n",
      "[[  0.       -11.190453 -15.960897 -17.554218]\n",
      " [-11.190453 -14.552313 -16.256601 -16.299404]\n",
      " [-15.960897 -16.256601 -14.841255 -11.641642]\n",
      " [-17.554218 -16.299404 -11.641642   0.      ]]\n",
      "current state-values (k = 20 ) :\n",
      "[[  0.        -11.425916  -16.299408  -17.926811 ]\n",
      " [-11.425916  -14.841259  -16.570332  -16.609547 ]\n",
      " [-16.299408  -16.570332  -15.105987  -11.8392935]\n",
      " [-17.926811  -16.609547  -11.8392935   0.       ]]\n",
      "current state-values (k = 21 ) :\n",
      "[[  0.        -11.641645  -16.609549  -18.268179 ]\n",
      " [-11.641645  -15.1059885 -16.857767  -16.893696 ]\n",
      " [-16.609549  -16.857767  -15.34853   -12.02038  ]\n",
      " [-18.268179  -16.893696  -12.02038     0.       ]]\n",
      "current state-values (k = 22 ) :\n",
      "[[  0.       -11.839295 -16.893698 -18.580938]\n",
      " [-11.839295 -15.348532 -17.121113 -17.154032]\n",
      " [-16.893698 -17.121113 -15.570746 -12.18629 ]\n",
      " [-18.580938 -17.154032 -12.18629    0.      ]]\n",
      "current state-values (k = 23 ) :\n",
      "[[  0.       -12.020381 -17.154032 -18.867485]\n",
      " [-12.020381 -15.570747 -17.362389 -17.39255 ]\n",
      " [-17.154032 -17.362389 -15.77434  -12.338295]\n",
      " [-18.867485 -17.39255  -12.338295   0.      ]]\n",
      "current state-values (k = 24 ) :\n",
      "[[  0.       -12.18629  -17.39255  -19.130016]\n",
      " [-12.18629  -15.77434  -17.583445 -17.611076]\n",
      " [-17.39255  -17.583445 -15.96087  -12.47756 ]\n",
      " [-19.130016 -17.611076 -12.47756    0.      ]]\n",
      "current state-values (k = 25 ) :\n",
      "[[  0.       -12.338295 -17.611076 -19.370546]\n",
      " [-12.338295 -15.96087  -17.785973 -17.811289]\n",
      " [-17.611076 -17.785973 -16.131767 -12.605154]\n",
      " [-19.370546 -17.811289 -12.605154   0.      ]]\n",
      "current state-values (k = 26 ) :\n",
      "[[  0.        -12.47756   -17.811289  -19.590918 ]\n",
      " [-12.47756   -16.131767  -17.971527  -17.994722 ]\n",
      " [-17.811289  -17.971527  -16.288342  -12.7220545]\n",
      " [-19.590918  -17.994722  -12.7220545   0.       ]]\n",
      "current state-values (k = 27 ) :\n",
      "[[  0.       -12.605154 -17.994722 -19.79282 ]\n",
      " [-12.605154 -16.288342 -18.141533 -18.162783]\n",
      " [-17.994722 -18.141533 -16.431793 -12.829158]\n",
      " [-19.79282  -18.162783 -12.829158   0.      ]]\n",
      "current state-values (k = 28 ) :\n",
      "[[  0.        -12.7220545 -18.162783  -19.977802 ]\n",
      " [-12.7220545 -16.431793  -18.297287  -18.316757 ]\n",
      " [-18.162783  -18.297287  -16.563223  -12.927284 ]\n",
      " [-19.977802  -18.316757  -12.927284    0.       ]]\n",
      "current state-values (k = 29 ) :\n",
      "[[  0.       -12.829158 -18.316757 -20.14728 ]\n",
      " [-12.829158 -16.563223 -18.439991 -18.457829]\n",
      " [-18.316757 -18.439991 -16.683638 -13.017187]\n",
      " [-20.14728  -18.457829 -13.017187   0.      ]]\n",
      "current state-values (k = 30 ) :\n",
      "[[  0.       -12.927284 -18.457829 -20.302555]\n",
      " [-12.927284 -16.683638 -18.570732 -18.587076]\n",
      " [-18.457829 -18.570732 -16.79396  -13.099556]\n",
      " [-20.302555 -18.587076 -13.099556   0.      ]]\n",
      "final state-values :\n",
      "[[  0.       -12.927284 -18.457829 -20.302555]\n",
      " [-12.927284 -16.683638 -18.570732 -18.587076]\n",
      " [-18.457829 -18.570732 -16.79396  -13.099556]\n",
      " [-20.302555 -18.587076 -13.099556   0.      ]]\n",
      "policy is stable in the loop : 0\n"
     ]
    }
   ],
   "source": [
    "agent = GridPolicyIterationAgent(env, policy, gamma=1.0)\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.3 (equation h/w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Policy Iteration\n",
    "### Exercise 4.7 (Example 4.2 Jack's Car Rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Value Iteration\n",
    "### Exercise 4.9 (Example 4.3 Gambler's Problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.10 (equation h/w)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow)",
   "language": "python",
   "name": "py3tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
