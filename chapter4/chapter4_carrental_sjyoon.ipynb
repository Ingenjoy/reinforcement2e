{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Rent Car World 2018-08-14 21:01:02.788934\n",
      "Policy evaluation (0) 2018-08-14 21:01:03.813660\n",
      "loop 1 : delta 191.1404, theta 0.0001 2018-08-14 21:01:45.640942\n",
      "loop 2 : delta 131.9191, theta 0.0001 2018-08-14 21:02:28.341482\n",
      "loop 3 : delta 88.6194, theta 0.0001 2018-08-14 21:03:12.451805\n",
      "loop 4 : delta 66.2761, theta 0.0001 2018-08-14 21:03:55.957540\n",
      "loop 5 : delta 52.3040, theta 0.0001 2018-08-14 21:04:38.448066\n",
      "loop 6 : delta 40.5043, theta 0.0001 2018-08-14 21:05:20.968686\n",
      "loop 7 : delta 31.5718, theta 0.0001 2018-08-14 21:06:03.675360\n",
      "loop 8 : delta 25.0090, theta 0.0001 2018-08-14 21:06:45.596833\n",
      "loop 9 : delta 20.7762, theta 0.0001 2018-08-14 21:07:26.761352\n",
      "loop 10 : delta 17.3732, theta 0.0001 2018-08-14 21:08:08.006027\n",
      "loop 11 : delta 14.4891, theta 0.0001 2018-08-14 21:08:49.311890\n",
      "loop 12 : delta 12.0544, theta 0.0001 2018-08-14 21:09:30.521525\n",
      "loop 13 : delta 10.0059, theta 0.0001 2018-08-14 21:10:11.508569\n",
      "loop 14 : delta 8.2881, theta 0.0001 2018-08-14 21:10:52.620919\n",
      "loop 15 : delta 6.8520, theta 0.0001 2018-08-14 21:11:33.883666\n",
      "loop 16 : delta 5.6550, theta 0.0001 2018-08-14 21:12:15.457162\n",
      "loop 17 : delta 4.6600, theta 0.0001 2018-08-14 21:12:57.429827\n",
      "loop 18 : delta 3.8349, theta 0.0001 2018-08-14 21:13:38.906677\n",
      "loop 19 : delta 3.1522, theta 0.0001 2018-08-14 21:14:21.093857\n",
      "loop 20 : delta 2.5884, theta 0.0001 2018-08-14 21:15:02.316501\n",
      "loop 21 : delta 2.1235, theta 0.0001 2018-08-14 21:15:44.166839\n",
      "loop 22 : delta 1.7407, theta 0.0001 2018-08-14 21:16:25.666148\n",
      "loop 23 : delta 1.4260, theta 0.0001 2018-08-14 21:17:06.686251\n",
      "loop 24 : delta 1.1675, theta 0.0001 2018-08-14 21:17:47.684296\n",
      "loop 25 : delta 0.9553, theta 0.0001 2018-08-14 21:18:29.382201\n",
      "loop 26 : delta 0.7814, theta 0.0001 2018-08-14 21:19:12.869872\n",
      "loop 27 : delta 0.6388, theta 0.0001 2018-08-14 21:19:54.756307\n",
      "loop 28 : delta 0.5221, theta 0.0001 2018-08-14 21:20:35.971906\n",
      "loop 29 : delta 0.4266, theta 0.0001 2018-08-14 21:21:17.458248\n",
      "loop 30 : delta 0.3485, theta 0.0001 2018-08-14 21:21:59.894118\n",
      "loop 31 : delta 0.2846, theta 0.0001 2018-08-14 21:22:42.797234\n",
      "loop 32 : delta 0.2324, theta 0.0001 2018-08-14 21:23:24.376825\n",
      "loop 33 : delta 0.1897, theta 0.0001 2018-08-14 21:24:05.764906\n",
      "loop 34 : delta 0.1548, theta 0.0001 2018-08-14 21:24:46.898339\n",
      "loop 35 : delta 0.1264, theta 0.0001 2018-08-14 21:25:27.712365\n",
      "loop 36 : delta 0.1031, theta 0.0001 2018-08-14 21:26:08.693337\n",
      "loop 37 : delta 0.0841, theta 0.0001 2018-08-14 21:26:50.317554\n",
      "loop 38 : delta 0.0686, theta 0.0001 2018-08-14 21:27:32.205968\n",
      "loop 39 : delta 0.0560, theta 0.0001 2018-08-14 21:28:17.703510\n",
      "loop 40 : delta 0.0457, theta 0.0001 2018-08-14 21:29:06.297758\n",
      "loop 41 : delta 0.0373, theta 0.0001 2018-08-14 21:29:49.802476\n",
      "loop 42 : delta 0.0304, theta 0.0001 2018-08-14 21:30:32.401780\n",
      "loop 43 : delta 0.0248, theta 0.0001 2018-08-14 21:31:13.897150\n",
      "loop 44 : delta 0.0202, theta 0.0001 2018-08-14 21:31:55.353412\n",
      "loop 45 : delta 0.0165, theta 0.0001 2018-08-14 21:32:36.435181\n",
      "loop 46 : delta 0.0134, theta 0.0001 2018-08-14 21:33:17.627743\n",
      "loop 47 : delta 0.0110, theta 0.0001 2018-08-14 21:33:58.569639\n",
      "loop 48 : delta 0.0089, theta 0.0001 2018-08-14 21:34:39.457392\n",
      "loop 49 : delta 0.0073, theta 0.0001 2018-08-14 21:35:20.331132\n",
      "loop 50 : delta 0.0059, theta 0.0001 2018-08-14 21:36:01.476526\n",
      "loop 51 : delta 0.0048, theta 0.0001 2018-08-14 21:36:42.363248\n",
      "loop 52 : delta 0.0040, theta 0.0001 2018-08-14 21:37:22.994344\n",
      "loop 53 : delta 0.0032, theta 0.0001 2018-08-14 21:38:03.959273\n",
      "loop 54 : delta 0.0026, theta 0.0001 2018-08-14 21:38:44.617437\n",
      "loop 55 : delta 0.0021, theta 0.0001 2018-08-14 21:39:25.423971\n",
      "loop 56 : delta 0.0017, theta 0.0001 2018-08-14 21:40:06.222485\n",
      "loop 57 : delta 0.0014, theta 0.0001 2018-08-14 21:40:47.385971\n",
      "loop 58 : delta 0.0012, theta 0.0001 2018-08-14 21:41:28.186516\n",
      "loop 59 : delta 0.0009, theta 0.0001 2018-08-14 21:42:08.965964\n",
      "loop 60 : delta 0.0008, theta 0.0001 2018-08-14 21:42:49.680281\n",
      "loop 61 : delta 0.0006, theta 0.0001 2018-08-14 21:43:30.418609\n",
      "loop 62 : delta 0.0005, theta 0.0001 2018-08-14 21:44:11.372535\n",
      "loop 63 : delta 0.0004, theta 0.0001 2018-08-14 21:44:52.001601\n",
      "loop 64 : delta 0.0003, theta 0.0001 2018-08-14 21:45:32.851252\n",
      "loop 65 : delta 0.0003, theta 0.0001 2018-08-14 21:46:14.947245\n",
      "loop 66 : delta 0.0002, theta 0.0001 2018-08-14 21:46:57.177540\n",
      "loop 67 : delta 0.0002, theta 0.0001 2018-08-14 21:47:38.240761\n",
      "loop 68 : delta 0.0002, theta 0.0001 2018-08-14 21:48:19.297995\n",
      "loop 69 : delta 0.0001, theta 0.0001 2018-08-14 21:49:00.450447\n",
      "loop 70 : delta 0.0001, theta 0.0001 2018-08-14 21:49:41.257958\n",
      "loop 71 : delta 0.0001, theta 0.0001 2018-08-14 21:50:21.912088\n",
      "Policy Improvement (0) 2018-08-14 21:50:21.912088\n",
      "318 policies are changed\n",
      "Policy evaluation (1) 2018-08-14 21:54:09.881442\n",
      "loop 1 : delta 64.0134, theta 0.0001 2018-08-14 21:54:49.909933\n",
      "loop 2 : delta 4.4455, theta 0.0001 2018-08-14 21:55:30.198064\n",
      "loop 3 : delta 2.0034, theta 0.0001 2018-08-14 21:56:10.193442\n",
      "loop 4 : delta 1.5196, theta 0.0001 2018-08-14 21:56:50.186318\n",
      "loop 5 : delta 1.3122, theta 0.0001 2018-08-14 21:57:30.002219\n",
      "loop 6 : delta 1.0846, theta 0.0001 2018-08-14 21:58:10.539038\n",
      "loop 7 : delta 0.8858, theta 0.0001 2018-08-14 21:58:50.591593\n",
      "loop 8 : delta 0.7214, theta 0.0001 2018-08-14 21:59:31.079761\n",
      "loop 9 : delta 0.5871, theta 0.0001 2018-08-14 22:00:11.096195\n",
      "loop 10 : delta 0.4776, theta 0.0001 2018-08-14 22:00:51.213899\n",
      "loop 11 : delta 0.3885, theta 0.0001 2018-08-14 22:01:31.132062\n",
      "loop 12 : delta 0.3159, theta 0.0001 2018-08-14 22:02:11.987862\n",
      "loop 13 : delta 0.2569, theta 0.0001 2018-08-14 22:02:54.211163\n",
      "loop 14 : delta 0.2090, theta 0.0001 2018-08-14 22:03:36.832525\n",
      "loop 15 : delta 0.1699, theta 0.0001 2018-08-14 22:04:19.582115\n",
      "loop 16 : delta 0.1382, theta 0.0001 2018-08-14 22:05:03.076798\n",
      "loop 17 : delta 0.1124, theta 0.0001 2018-08-14 22:05:43.736917\n",
      "loop 18 : delta 0.0914, theta 0.0001 2018-08-14 22:06:24.179484\n",
      "loop 19 : delta 0.0743, theta 0.0001 2018-08-14 22:07:04.494713\n",
      "loop 20 : delta 0.0604, theta 0.0001 2018-08-14 22:07:44.894166\n",
      "loop 21 : delta 0.0491, theta 0.0001 2018-08-14 22:08:25.152241\n",
      "loop 22 : delta 0.0400, theta 0.0001 2018-08-14 22:09:06.044008\n",
      "loop 23 : delta 0.0325, theta 0.0001 2018-08-14 22:09:46.250949\n",
      "loop 24 : delta 0.0264, theta 0.0001 2018-08-14 22:10:26.474933\n",
      "loop 25 : delta 0.0215, theta 0.0001 2018-08-14 22:11:07.361718\n",
      "loop 26 : delta 0.0175, theta 0.0001 2018-08-14 22:11:47.869434\n",
      "loop 27 : delta 0.0142, theta 0.0001 2018-08-14 22:12:28.159965\n",
      "loop 28 : delta 0.0116, theta 0.0001 2018-08-14 22:13:08.334822\n",
      "loop 29 : delta 0.0094, theta 0.0001 2018-08-14 22:13:48.536799\n",
      "loop 30 : delta 0.0076, theta 0.0001 2018-08-14 22:14:28.776828\n",
      "loop 31 : delta 0.0062, theta 0.0001 2018-08-14 22:15:09.131162\n",
      "loop 32 : delta 0.0051, theta 0.0001 2018-08-14 22:15:49.998860\n",
      "loop 33 : delta 0.0041, theta 0.0001 2018-08-14 22:16:30.423884\n",
      "loop 34 : delta 0.0033, theta 0.0001 2018-08-14 22:17:10.692991\n",
      "loop 35 : delta 0.0027, theta 0.0001 2018-08-14 22:17:50.994182\n",
      "loop 36 : delta 0.0022, theta 0.0001 2018-08-14 22:18:31.123944\n",
      "loop 37 : delta 0.0018, theta 0.0001 2018-08-14 22:19:11.508328\n",
      "loop 38 : delta 0.0015, theta 0.0001 2018-08-14 22:19:51.659626\n",
      "loop 39 : delta 0.0012, theta 0.0001 2018-08-14 22:20:32.734877\n",
      "loop 40 : delta 0.0010, theta 0.0001 2018-08-14 22:21:13.258688\n",
      "loop 41 : delta 0.0008, theta 0.0001 2018-08-14 22:21:53.400456\n",
      "loop 42 : delta 0.0006, theta 0.0001 2018-08-14 22:22:33.675078\n",
      "loop 43 : delta 0.0005, theta 0.0001 2018-08-14 22:23:13.907085\n",
      "loop 44 : delta 0.0004, theta 0.0001 2018-08-14 22:23:54.171151\n",
      "loop 45 : delta 0.0003, theta 0.0001 2018-08-14 22:24:34.589660\n",
      "loop 46 : delta 0.0003, theta 0.0001 2018-08-14 22:25:15.514511\n",
      "loop 47 : delta 0.0002, theta 0.0001 2018-08-14 22:25:56.440364\n",
      "loop 48 : delta 0.0002, theta 0.0001 2018-08-14 22:26:36.777651\n",
      "loop 49 : delta 0.0002, theta 0.0001 2018-08-14 22:27:16.888843\n",
      "loop 50 : delta 0.0001, theta 0.0001 2018-08-14 22:27:57.111862\n",
      "loop 51 : delta 0.0001, theta 0.0001 2018-08-14 22:28:37.267665\n",
      "Policy Improvement (1) 2018-08-14 22:28:37.267665\n",
      "260 policies are changed\n",
      "Policy evaluation (2) 2018-08-14 22:32:25.872202\n",
      "loop 1 : delta 4.2017, theta 0.0001 2018-08-14 22:33:06.316773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 2 : delta 2.7978, theta 0.0001 2018-08-14 22:33:46.951381\n",
      "loop 3 : delta 1.8926, theta 0.0001 2018-08-14 22:34:27.720818\n",
      "loop 4 : delta 1.3512, theta 0.0001 2018-08-14 22:35:08.331808\n",
      "loop 5 : delta 0.9218, theta 0.0001 2018-08-14 22:35:48.868624\n",
      "loop 6 : delta 0.6108, theta 0.0001 2018-08-14 22:36:29.316206\n",
      "loop 7 : delta 0.4029, theta 0.0001 2018-08-14 22:37:09.877094\n",
      "loop 8 : delta 0.2699, theta 0.0001 2018-08-14 22:37:50.390878\n",
      "loop 9 : delta 0.1940, theta 0.0001 2018-08-14 22:38:30.918646\n",
      "loop 10 : delta 0.1468, theta 0.0001 2018-08-14 22:39:11.591853\n",
      "loop 11 : delta 0.1142, theta 0.0001 2018-08-14 22:39:52.234410\n",
      "loop 12 : delta 0.0933, theta 0.0001 2018-08-14 22:40:33.117148\n",
      "loop 13 : delta 0.0761, theta 0.0001 2018-08-14 22:41:13.855501\n",
      "loop 14 : delta 0.0620, theta 0.0001 2018-08-14 22:41:54.524343\n",
      "loop 15 : delta 0.0505, theta 0.0001 2018-08-14 22:42:35.152436\n",
      "loop 16 : delta 0.0411, theta 0.0001 2018-08-14 22:43:15.717301\n",
      "loop 17 : delta 0.0335, theta 0.0001 2018-08-14 22:43:56.332354\n",
      "loop 18 : delta 0.0273, theta 0.0001 2018-08-14 22:44:36.918302\n",
      "loop 19 : delta 0.0222, theta 0.0001 2018-08-14 22:45:17.411004\n",
      "loop 20 : delta 0.0181, theta 0.0001 2018-08-14 22:45:57.828005\n",
      "loop 21 : delta 0.0147, theta 0.0001 2018-08-14 22:46:38.203369\n",
      "loop 22 : delta 0.0120, theta 0.0001 2018-08-14 22:47:18.714144\n",
      "loop 23 : delta 0.0097, theta 0.0001 2018-08-14 22:47:59.336190\n",
      "loop 24 : delta 0.0079, theta 0.0001 2018-08-14 22:48:39.882007\n",
      "loop 25 : delta 0.0064, theta 0.0001 2018-08-14 22:49:20.654479\n",
      "loop 26 : delta 0.0052, theta 0.0001 2018-08-14 22:50:01.086993\n",
      "loop 27 : delta 0.0043, theta 0.0001 2018-08-14 22:50:41.551620\n",
      "loop 28 : delta 0.0035, theta 0.0001 2018-08-14 22:51:22.116513\n",
      "loop 29 : delta 0.0028, theta 0.0001 2018-08-14 22:52:02.479903\n",
      "loop 30 : delta 0.0023, theta 0.0001 2018-08-14 22:52:43.009672\n",
      "loop 31 : delta 0.0019, theta 0.0001 2018-08-14 22:53:23.451237\n",
      "loop 32 : delta 0.0015, theta 0.0001 2018-08-14 22:54:04.078296\n",
      "loop 33 : delta 0.0012, theta 0.0001 2018-08-14 22:54:44.784594\n",
      "loop 34 : delta 0.0010, theta 0.0001 2018-08-14 22:55:25.690395\n",
      "loop 35 : delta 0.0008, theta 0.0001 2018-08-14 22:56:06.900002\n",
      "loop 36 : delta 0.0007, theta 0.0001 2018-08-14 22:56:47.682477\n",
      "loop 37 : delta 0.0005, theta 0.0001 2018-08-14 22:57:28.308531\n",
      "loop 38 : delta 0.0004, theta 0.0001 2018-08-14 22:58:08.910552\n",
      "loop 39 : delta 0.0004, theta 0.0001 2018-08-14 22:58:49.706059\n",
      "loop 40 : delta 0.0003, theta 0.0001 2018-08-14 22:59:30.325096\n",
      "loop 41 : delta 0.0002, theta 0.0001 2018-08-14 23:00:10.955135\n",
      "loop 42 : delta 0.0002, theta 0.0001 2018-08-14 23:00:51.619815\n",
      "loop 43 : delta 0.0002, theta 0.0001 2018-08-14 23:01:32.321097\n",
      "loop 44 : delta 0.0001, theta 0.0001 2018-08-14 23:02:13.032378\n",
      "loop 45 : delta 0.0001, theta 0.0001 2018-08-14 23:02:53.789757\n",
      "loop 46 : delta 0.0001, theta 0.0001 2018-08-14 23:03:39.644289\n",
      "Policy Improvement (2) 2018-08-14 23:03:39.644289\n",
      "82 policies are changed\n",
      "Policy evaluation (3) 2018-08-14 23:07:49.739878\n",
      "loop 1 : delta 0.5303, theta 0.0001 2018-08-14 23:08:37.547578\n",
      "loop 2 : delta 0.1610, theta 0.0001 2018-08-14 23:09:19.422502\n",
      "loop 3 : delta 0.0753, theta 0.0001 2018-08-14 23:10:00.285674\n",
      "loop 4 : delta 0.0454, theta 0.0001 2018-08-14 23:10:40.830514\n",
      "loop 5 : delta 0.0309, theta 0.0001 2018-08-14 23:11:21.813518\n",
      "loop 6 : delta 0.0205, theta 0.0001 2018-08-14 23:12:02.365068\n",
      "loop 7 : delta 0.0132, theta 0.0001 2018-08-14 23:12:43.420594\n",
      "loop 8 : delta 0.0085, theta 0.0001 2018-08-14 23:13:24.560015\n",
      "loop 9 : delta 0.0055, theta 0.0001 2018-08-14 23:14:05.565078\n",
      "loop 10 : delta 0.0037, theta 0.0001 2018-08-14 23:14:46.511993\n",
      "loop 11 : delta 0.0027, theta 0.0001 2018-08-14 23:15:27.454884\n",
      "loop 12 : delta 0.0021, theta 0.0001 2018-08-14 23:16:08.369275\n",
      "loop 13 : delta 0.0017, theta 0.0001 2018-08-14 23:16:48.919155\n",
      "loop 14 : delta 0.0014, theta 0.0001 2018-08-14 23:17:29.298528\n",
      "loop 15 : delta 0.0011, theta 0.0001 2018-08-14 23:18:10.145171\n",
      "loop 16 : delta 0.0009, theta 0.0001 2018-08-14 23:18:51.112261\n",
      "loop 17 : delta 0.0008, theta 0.0001 2018-08-14 23:19:31.599974\n",
      "loop 18 : delta 0.0006, theta 0.0001 2018-08-14 23:20:12.480711\n",
      "loop 19 : delta 0.0005, theta 0.0001 2018-08-14 23:20:53.133807\n",
      "loop 20 : delta 0.0004, theta 0.0001 2018-08-14 23:21:33.945387\n",
      "loop 21 : delta 0.0003, theta 0.0001 2018-08-14 23:22:14.590969\n",
      "loop 22 : delta 0.0003, theta 0.0001 2018-08-14 23:22:55.185942\n",
      "loop 23 : delta 0.0002, theta 0.0001 2018-08-14 23:23:35.808016\n",
      "loop 24 : delta 0.0002, theta 0.0001 2018-08-14 23:24:16.600484\n",
      "loop 25 : delta 0.0001, theta 0.0001 2018-08-14 23:24:57.261637\n",
      "loop 26 : delta 0.0001, theta 0.0001 2018-08-14 23:25:38.305831\n",
      "loop 27 : delta 0.0001, theta 0.0001 2018-08-14 23:26:18.947904\n",
      "Policy Improvement (3) 2018-08-14 23:26:18.947904\n",
      "10 policies are changed\n",
      "Policy evaluation (4) 2018-08-14 23:30:10.971604\n",
      "loop 1 : delta 0.0519, theta 0.0001 2018-08-14 23:30:51.814715\n",
      "loop 2 : delta 0.0074, theta 0.0001 2018-08-14 23:31:32.544046\n",
      "loop 3 : delta 0.0033, theta 0.0001 2018-08-14 23:32:13.236277\n",
      "loop 4 : delta 0.0019, theta 0.0001 2018-08-14 23:32:53.949596\n",
      "loop 5 : delta 0.0011, theta 0.0001 2018-08-14 23:33:35.125658\n",
      "loop 6 : delta 0.0006, theta 0.0001 2018-08-14 23:34:16.210936\n",
      "loop 7 : delta 0.0004, theta 0.0001 2018-08-14 23:34:57.143833\n",
      "loop 8 : delta 0.0002, theta 0.0001 2018-08-14 23:35:37.978443\n",
      "loop 9 : delta 0.0001, theta 0.0001 2018-08-14 23:36:19.159506\n",
      "loop 10 : delta 0.0001, theta 0.0001 2018-08-14 23:37:00.073316\n",
      "Policy Improvement (4) 2018-08-14 23:37:00.073316\n",
      "0 policies are changed\n",
      "End Rent Car World 2018-08-14 23:40:53.394885\n",
      "Running Time 2:39:50.605951\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example 4.2 Jack's Car Rental\n",
    "\n",
    "Author : SeongJin Yoon\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "MIN = 0\n",
    "MAX = 1\n",
    "\n",
    "class ConfigDict(dict):\n",
    "    def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs)\n",
    "    def __getattr__(self, name): return self[name]\n",
    "    def __setattr__(self, name, value): self[name] = value\n",
    "    def __delattr__(self, name): del self[name]\n",
    "        \n",
    "config = ConfigDict()\n",
    "config.env = ConfigDict(max_managed_cars = 20, max_movable_cars = 5, num_branch = 2)\n",
    "config.branch1 = ConfigDict(lambda_rent = 3, lambda_return = 3)\n",
    "config.branch2 = ConfigDict(lambda_rent = 4, lambda_return = 2)\n",
    "config.value = ConfigDict(discount = 0.9, theta = 1e-4)\n",
    "config.poisson = ConfigDict(upperbound = 11)\n",
    "config.plot = ConfigDict(save_dir = './sjyoon/')\n",
    "\n",
    "class Plot():\n",
    "    def __init__(self, nrows, ncols, num_ticks, coord_list):\n",
    "        self.fig_idx = 0\n",
    "\n",
    "        self.coord_list = coord_list\n",
    "        self.xticks = list(range(num_ticks+1))\n",
    "        self.yticks = list(reversed(range(num_ticks+1)))\n",
    "        \n",
    "        _, self.axes = plt.subplots(nrows=nrows, ncols=ncols,  figsize=(40, 20))\n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "        self.axes = self.axes.flatten()\n",
    "\n",
    "    # plot a policy/state value matrix\n",
    "    def draw_heatmap(self, data, labels):\n",
    "        fig = sns.heatmap(data, cmap=\"YlGnBu\", ax=self.axes[self.fig_idx])\n",
    "        fig.set_xticks(self.xticks)\n",
    "        fig.set_yticks(self.yticks)\n",
    "        fig.set_ylabel(labels[0], fontsize=30)\n",
    "        fig.set_xlabel(labels[1], fontsize=30)\n",
    "        fig.set_title(labels[2], fontsize=30)\n",
    "        self.fig_idx += 1\n",
    "\n",
    "    def save(self, title):\n",
    "        plt.savefig(title)\n",
    "\n",
    "    def show(self):\n",
    "        plt.show()\n",
    "\n",
    "    def close(self):\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "class Poisson():\n",
    "    def __init__(self):\n",
    "        self.dist = dict()\n",
    "        \n",
    "    def prob(self, n, mean):\n",
    "        key = n * 10 + mean\n",
    "        if key not in self.dist.keys():\n",
    "            self.dist[key] = math.exp(-mean) * pow(mean, n) / math.factorial(n)\n",
    "\n",
    "        return self.dist[key]\n",
    "    \n",
    "    def __call__(self, n, mean):\n",
    "        return self.prob(n, mean)\n",
    "\n",
    "\n",
    "class Reward(Enum):\n",
    "    \"\"\"Reward classes.\"\"\"\n",
    "    rent = 1\n",
    "    move = 2\n",
    "\n",
    "class Transaction():\n",
    "    \"\"\"Request and Return transaction classes.\"\"\"\n",
    "    def __init__(self, dist, mean):\n",
    "        self.dist = dist\n",
    "        self.mean = mean\n",
    "\n",
    "    def prob(self, num_tx):\n",
    "        return self.dist.prob(num_tx, self.mean)\n",
    "    \n",
    "class Environment():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.prepare_environment()\n",
    "        \n",
    "        self.branch1 = Branch(config.branch1)\n",
    "        self.branch2 = Branch(config.branch2)\n",
    "        self.branch_list = [self.branch1, self.branch2]\n",
    "        \n",
    "        poisson_dist = Poisson()\n",
    "        self.request1 = Transaction(poisson_dist, config.branch1.lambda_rent)\n",
    "        self.request2 = Transaction(poisson_dist, config.branch2.lambda_rent)\n",
    "        self.return1 = Transaction(poisson_dist, config.branch1.lambda_return)\n",
    "        self.return2 = Transaction(poisson_dist, config.branch2.lambda_return)\n",
    "        \n",
    "\n",
    "    def prepare_environment(self):\n",
    "        self.num_state = config.env.max_managed_cars + 1\n",
    "        self.num_action = config.env.max_movable_cars # max number of cars to be moved\n",
    "        self.num_request = config.poisson.upperbound\n",
    "        self.num_return = config.poisson.upperbound\n",
    "        \n",
    "        \n",
    "        self.state_list = self.make_pair_list(self.num_state)\n",
    "        self.action_list = list(range(0, self.num_action+1)) + list(range(-1, -(self.num_action+1), -1))\n",
    "        self.request_list = self.make_pair_list(self.num_request)\n",
    "        self.return_list = self.make_pair_list(self.num_return)\n",
    "        self.reward_list = {Reward.rent : 10, Reward.move : -2}\n",
    "        return\n",
    "    \n",
    "    def make_pair_list(self, num_pair):\n",
    "        return list(itertools.product(range(num_pair), repeat=2))\n",
    "    \n",
    "    def get_statelist(self):\n",
    "        return self.state_list\n",
    "    \n",
    "    def get_actionlist(self):\n",
    "        return self.action_list\n",
    "\n",
    "    def get_requestlist(self):\n",
    "        return self.request_list\n",
    "\n",
    "    def get_returnlist(self):\n",
    "        return self.return_list\n",
    "\n",
    "    def get_num_state(self):\n",
    "        return self.num_state\n",
    "\n",
    "    def get_num_action(self):\n",
    "        return self.num_action\n",
    "    \n",
    "    def get_state(self):\n",
    "        state = tuple((self.branch1.get_state(), self.branch2.get_state()))\n",
    "        return state\n",
    "\n",
    "    def get_reward(self, reward_type):\n",
    "        return self.reward_list[reward_type]\n",
    "\n",
    "    def rent_prob(self, requests):\n",
    "        r1, r2 = requests\n",
    "        return self.request1.prob(r1) * self.request2.prob(r2)\n",
    "            \n",
    "    def return_prob(self, returns):\n",
    "        r1, r2 = returns\n",
    "        return self.return1.prob(r1) * self.return2.prob(r2)\n",
    "\n",
    "    def validate(self, state, action):\n",
    "        self.reset_state(state)\n",
    "        \n",
    "        from_branch = self.branch1\n",
    "        to_branch = self.branch2\n",
    "        requests = action\n",
    "        \n",
    "        if action < 0:\n",
    "            from_branch = self.branch2\n",
    "            to_branch = self.branch1\n",
    "            requests = -action\n",
    "        \n",
    "        if from_branch.get_available_cars() < requests \\\n",
    "            or to_branch.get_acceptable_cars() < requests:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    def lookahead_do_action(self, state, action):\n",
    "        \"\"\" move cars from one branch to another branch\"\"\"\n",
    "\n",
    "        if self.validate(state, action)  is False:\n",
    "            return 0\n",
    "\n",
    "        self.reset_state(state)\n",
    "\n",
    "        from_branch = self.branch1\n",
    "        to_branch = self.branch2\n",
    "        requests = action\n",
    "        \n",
    "        if action < 0:\n",
    "            from_branch = self.branch2\n",
    "            to_branch = self.branch1\n",
    "            requests = -action\n",
    "       \n",
    "        cars_move_from = from_branch.move_from(requests)\n",
    "        cars_move_info = to_branch.move_into(requests)\n",
    "        \n",
    "        assert cars_move_from == cars_move_info\n",
    "\n",
    "        reward = requests*self.get_reward(Reward.move)\n",
    "        return self.get_state(), reward\n",
    "\n",
    "    def lookahead_rent_cars(self, state, requests):\n",
    "        self.reset_state(state)\n",
    "        \n",
    "        r1, r2 = requests\n",
    "        rent_cars1 = self.branch1.rent_cars(r1)\n",
    "        rent_cars2 = self.branch2.rent_cars(r2)\n",
    "       \n",
    "        total_rent_cars = rent_cars1 + rent_cars2\n",
    "        reward = total_rent_cars*self.get_reward(Reward.rent)\n",
    "        \n",
    "        return self.get_state(), reward\n",
    "\n",
    "    def lookahead_return_cars(self, state, returns):\n",
    "        self.reset_state(state)\n",
    "            \n",
    "        r1, r2 = returns\n",
    "        self.branch1.return_cars(r1)\n",
    "        self.branch2.return_cars(r2)\n",
    "        \n",
    "        return self.get_state()\n",
    "    \n",
    "    def reset_state(self, state):\n",
    "        s1, s2 = state\n",
    "        self.branch1.set_state(s1)\n",
    "        self.branch2.set_state(s2)\n",
    "\n",
    "class Branch():\n",
    "    def __init__(self, branch):\n",
    "        self.branch = branch\n",
    "        self.state_range = [0,config.env.max_managed_cars]\n",
    "        self.state = config.env.max_managed_cars\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "    \n",
    "    def set_state(self, state):\n",
    "        assert self.in_range(state)\n",
    "        self.state = state\n",
    "\n",
    "    def in_range(self, state):\n",
    "        if self.state_range[MIN] <= state \\\n",
    "            and state <= self.state_range[MAX]:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_available_cars(self):\n",
    "        return self.state - self.state_range[MIN]\n",
    "    \n",
    "    def get_acceptable_cars(self):\n",
    "        return self.state_range[MAX] - self.state\n",
    "\n",
    "    def rent_cars(self, request_cars):\n",
    "        available_cars = self.state - self.state_range[MIN]\n",
    "        \n",
    "        if available_cars < request_cars:\n",
    "            rent_cars = available_cars\n",
    "        else:\n",
    "            rent_cars = request_cars\n",
    "        \n",
    "        self.state -= rent_cars\n",
    "        return rent_cars\n",
    "    \n",
    "    def return_cars(self, request_cars):\n",
    "        acceptable_cars = self.state_range[MAX] - self.state\n",
    "        \n",
    "        if acceptable_cars < request_cars:\n",
    "            return_cars = acceptable_cars\n",
    "        else:\n",
    "            return_cars = request_cars\n",
    "\n",
    "        self.state += return_cars\n",
    "        return return_cars\n",
    "\n",
    "    def move_from(self, request_cars):\n",
    "        if request_cars > config.env.max_movable_cars:\n",
    "            return 0\n",
    "        \n",
    "        available_cars = self.get_available_cars()\n",
    "        \n",
    "        if available_cars < request_cars:\n",
    "            move_cars = available_cars\n",
    "        else:\n",
    "            move_cars = request_cars\n",
    "        \n",
    "        self.state -= move_cars\n",
    "        return move_cars\n",
    "\n",
    "    def move_into(self, request_cars):\n",
    "        if request_cars > config.env.max_movable_cars:\n",
    "            return 0\n",
    "        \n",
    "        acceptable_cars = self.get_acceptable_cars()\n",
    "        \n",
    "        if acceptable_cars <= request_cars:\n",
    "            move_cars = acceptable_cars\n",
    "        else:\n",
    "            move_cars = request_cars\n",
    "\n",
    "        self.state += move_cars\n",
    "        return move_cars\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, env):\n",
    "        \n",
    "        self.env = env\n",
    "        self.qurey_environment()\n",
    "        \n",
    "        self.plot = Plot(2, 3, self.num_state, self.state_list)\n",
    "        self.policy_labels = ['# of cars in branch 1', '# of cars in branch 2', 'Policy']\n",
    "        self.v_labels = ['# of cars in branch 1', '# of cars in branch 2', 'Value Function']\n",
    "\n",
    "\n",
    "    def qurey_environment(self):\n",
    "        self.num_state = self.env.get_num_state()\n",
    "        self.num_action = self.env.get_num_action()\n",
    "\n",
    "        self.state_list = self.env.get_statelist()\n",
    "        self.action_list = self.env.get_actionlist()\n",
    "        self.request_list = self.env.get_requestlist()\n",
    "        self.return_list = self.env.get_returnlist()\n",
    "        \n",
    "    \n",
    "    def policy_iteration(self):\n",
    "        \n",
    "        # 1. Initialize\n",
    "        self.policy = np.zeros((self.num_state, self.num_state), dtype=np.int8)\n",
    "        self.value_function = np.zeros((self.num_state, self.num_state))\n",
    "\n",
    "        iter_count = 0\n",
    "        policy_stable = False\n",
    "        while policy_stable is False:            \n",
    "            # 3. Visualization of Policy\n",
    "            self.policy_labels[2] = \"Policy %d\" % (iter_count)\n",
    "            self.plot.draw_heatmap(np.flipud(self.policy), self.policy_labels)\n",
    "            filename = config.plot.save_dir + \"figure_4_2_rentcar_%d.png\" % (iter_count)\n",
    "            self.plot.save(filename)\n",
    "\n",
    "            # 2. Policy Evaluation\n",
    "            print(\"Policy evaluation (%d)\" % (iter_count), dt.datetime.now())\n",
    "            self.policy_evaluation()\n",
    "\n",
    "            # 3. Policy Improvement\n",
    "            print(\"Policy Improvement (%d)\" % (iter_count), dt.datetime.now())\n",
    "            policy_stable = self.policy_improvement()\n",
    "\n",
    "            iter_count += 1\n",
    "\n",
    "        # 4. Visualization of Value Function\n",
    "        self.v_labels[2] = \"Value Function %d\" % (iter_count)\n",
    "        self.plot.draw_heatmap(np.flipud(self.value_function) , self.v_labels)\n",
    "        filename = config.plot.save_dir + \"figure_4_2_rentcar_final.png\"\n",
    "        self.plot.save(filename)       \n",
    "        self.plot.close()\n",
    "\n",
    "    def policy_evaluation(self):\n",
    "        \n",
    "        theta = config.value.theta\n",
    "        loop_count = 1\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for state in self.state_list:\n",
    "                s1, s2 = state\n",
    "                v = self.value_function[s1, s2]\n",
    "                action_idx = self.policy[s1, s2]\n",
    "                new_value = self.calc_qvalue(state, action_idx)\n",
    "                self.value_function[s1, s2] = new_value\n",
    "                \n",
    "                delta = max(delta, math.fabs(v - new_value)) \n",
    "                \n",
    "            print(\"loop %d : delta %.4f, theta %.4f\" % (loop_count, delta, theta), dt.datetime.now())\n",
    "            #print(self.V.get_array())\n",
    "            loop_count += 1\n",
    "            \n",
    "            if delta < theta:\n",
    "                break\n",
    "        \n",
    "    def policy_improvement(self):\n",
    "        \n",
    "        change_count = 0\n",
    "        old_policy_sum = np.sum(self.policy)\n",
    "        \n",
    "        for state in self.state_list:\n",
    "            s1, s2 = state\n",
    "            old_action = self.policy[s1, s2]\n",
    "\n",
    "            # calculate return for each action\n",
    "            qvalue_list = []\n",
    "            for action in self.action_list:\n",
    "                if self.env.validate(state, action):\n",
    "                    qvalue_list.append(self.calc_qvalue(state, action))\n",
    "                else:\n",
    "                    qvalue_list.append(-float('inf'))\n",
    "            \n",
    "            # pick baset action\n",
    "            best_action = self.action_list[self.pick_best(qvalue_list)]\n",
    "            self.policy[s1, s2] = best_action\n",
    "            \n",
    "            if old_action != best_action:\n",
    "                change_count += 1\n",
    "                \n",
    "        policy_stable = True\n",
    "        if old_policy_sum != np.sum(self.policy):\n",
    "            policy_stable = False\n",
    "\n",
    "        print(\"%d policies are changed\" % (change_count))            \n",
    "        #print(self.policy.get_array())             \n",
    "        return policy_stable\n",
    "    \n",
    "    def pick_best(self, candidates):\n",
    "        best_idx = np.argmax(candidates)\n",
    "        return best_idx\n",
    "    \n",
    "    def calc_qvalue(self, state, action):\n",
    "       \n",
    "        new_state, immediate_reward = self.env.lookahead_do_action(state, action)\n",
    "        discounted_return = self.lookahead_daily_transaction(new_state)\n",
    " \n",
    "        exptected_return = immediate_reward + discounted_return\n",
    "        return exptected_return\n",
    "    \n",
    "    def lookahead_daily_transaction(self, state):\n",
    "        discount = config.value.discount\n",
    "        discounted_return = 0\n",
    "        for requests in self.request_list:\n",
    "            new_state, reward = self.env.lookahead_rent_cars(state, requests)\n",
    "            prob_request = self.env.rent_prob(requests)\n",
    "\n",
    "            for returns in self.return_list:\n",
    "                new_state2 = self.env.lookahead_return_cars(new_state, returns)\n",
    "                prob_return = self.env.return_prob(returns)\n",
    "                prob = prob_request * prob_return\n",
    "                s1, s2 = new_state2\n",
    "                discounted_return += prob * \\\n",
    "                    (reward + discount * self.value_function[s1, s2] )\n",
    " \n",
    "        return discounted_return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    begin_time = dt.datetime.now()\n",
    "    print(\"Start Rent Car World\", begin_time)\n",
    "    env = Environment()\n",
    "    agent = Agent(env)\n",
    "    agent.policy_iteration()\n",
    "    end_time = dt.datetime.now()\n",
    "    print(\"End Rent Car World\", end_time)\n",
    "    print(\"Running Time\", end_time - begin_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLGosu",
   "language": "python",
   "name": "rlgosu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
